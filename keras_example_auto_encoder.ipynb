{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from IPython.display import SVG\n",
    "print(tf.__version__)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28*28)) / 255.0\n",
    "x_test = x_test.reshape((-1, 28*28)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)   (60000,)\n",
      "(10000, 784)   (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.简单的自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "code_dim = 32\n",
    "inputs = layers.Input(shape=(x_train.shape[1],), name='inputs')\n",
    "code = layers.Dense(code_dim, activation='relu', name='code')(inputs)\n",
    "outputs = layers.Dense(x_train.shape[1], activation='softmax', name='outputs')(code)\n",
    "\n",
    "auto_encoder = keras.Model(inputs, outputs)\n",
    "auto_encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(auto_encoder, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.Model(inputs,code)\n",
    "keras.utils.plot_model(encoder, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "decoder_input = keras.Input((code_dim,))\n",
    "decoder_output = auto_encoder.layers[-1](decoder_input)\n",
    "decoder = keras.Model(decoder_input, decoder_output)\n",
    "keras.utils.plot_model(decoder, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting pydot\n",
      "  Downloading https://pypi.doubanio.com/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting graphviz\n",
      "  Downloading https://pypi.doubanio.com/packages/5c/b1/016e657586843f40b4daa66127ce1ee9e3285ff15baf5d80946644a98aeb/graphviz-0.11.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.5/dist-packages (from pydot) (2.4.0)\n",
      "Installing collected packages: pydot, graphviz\n",
      "Successfully installed graphviz-0.11.1 pydot-1.4.1\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot graphviz -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 04:54:58.505131 140010574141184 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "54000/54000 [==============================] - 6s 118us/sample - loss: 0.7059 - val_loss: 0.6798\n",
      "Epoch 2/100\n",
      "54000/54000 [==============================] - 5s 94us/sample - loss: 0.6798 - val_loss: 0.6744\n",
      "Epoch 3/100\n",
      "54000/54000 [==============================] - 5s 83us/sample - loss: 0.6768 - val_loss: 0.6732\n",
      "Epoch 4/100\n",
      "54000/54000 [==============================] - 5s 91us/sample - loss: 0.6759 - val_loss: 0.6725\n",
      "Epoch 5/100\n",
      "54000/54000 [==============================] - 5s 98us/sample - loss: 0.6753 - val_loss: 0.6722\n",
      "Epoch 6/100\n",
      "54000/54000 [==============================] - 5s 100us/sample - loss: 0.6751 - val_loss: 0.6722\n",
      "Epoch 7/100\n",
      "54000/54000 [==============================] - 5s 91us/sample - loss: 0.6749 - val_loss: 0.6719\n",
      "Epoch 8/100\n",
      "54000/54000 [==============================] - 5s 92us/sample - loss: 0.6747 - val_loss: 0.6718\n",
      "Epoch 9/100\n",
      "54000/54000 [==============================] - 4s 77us/sample - loss: 0.6746 - val_loss: 0.6717\n",
      "Epoch 10/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6745 - val_loss: 0.6715\n",
      "Epoch 11/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6744 - val_loss: 0.6715\n",
      "Epoch 12/100\n",
      "54000/54000 [==============================] - 4s 80us/sample - loss: 0.6743 - val_loss: 0.6715\n",
      "Epoch 13/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6742 - val_loss: 0.6715\n",
      "Epoch 14/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6742 - val_loss: 0.6714\n",
      "Epoch 15/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6741 - val_loss: 0.6714\n",
      "Epoch 16/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6741 - val_loss: 0.6713\n",
      "Epoch 17/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6740 - val_loss: 0.6714\n",
      "Epoch 18/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6740 - val_loss: 0.6712\n",
      "Epoch 19/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6740 - val_loss: 0.6711\n",
      "Epoch 20/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6739 - val_loss: 0.6711\n",
      "Epoch 21/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6739 - val_loss: 0.6711\n",
      "Epoch 22/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6738 - val_loss: 0.6711\n",
      "Epoch 23/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6738 - val_loss: 0.6710\n",
      "Epoch 24/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6738 - val_loss: 0.6710\n",
      "Epoch 25/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6737 - val_loss: 0.6710\n",
      "Epoch 26/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6737 - val_loss: 0.6710\n",
      "Epoch 27/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6737 - val_loss: 0.6711\n",
      "Epoch 28/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6736 - val_loss: 0.6709\n",
      "Epoch 29/100\n",
      "54000/54000 [==============================] - 3s 61us/sample - loss: 0.6736 - val_loss: 0.6708\n",
      "Epoch 30/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6735 - val_loss: 0.6707\n",
      "Epoch 31/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6735 - val_loss: 0.6709\n",
      "Epoch 32/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6734 - val_loss: 0.6707\n",
      "Epoch 33/100\n",
      "54000/54000 [==============================] - 4s 65us/sample - loss: 0.6734 - val_loss: 0.6707\n",
      "Epoch 34/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6734 - val_loss: 0.6706\n",
      "Epoch 35/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6733 - val_loss: 0.6706\n",
      "Epoch 36/100\n",
      "54000/54000 [==============================] - 3s 62us/sample - loss: 0.6733 - val_loss: 0.6705\n",
      "Epoch 37/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6732 - val_loss: 0.6704\n",
      "Epoch 38/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6732 - val_loss: 0.6705\n",
      "Epoch 39/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6732 - val_loss: 0.6704\n",
      "Epoch 40/100\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.6731 - val_loss: 0.6704\n",
      "Epoch 41/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6731 - val_loss: 0.6703\n",
      "Epoch 42/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6730 - val_loss: 0.6704\n",
      "Epoch 43/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6730 - val_loss: 0.6703\n",
      "Epoch 44/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6730 - val_loss: 0.6702\n",
      "Epoch 45/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6730 - val_loss: 0.6703\n",
      "Epoch 46/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6729 - val_loss: 0.6701\n",
      "Epoch 47/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6729 - val_loss: 0.6702\n",
      "Epoch 48/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6729 - val_loss: 0.6701\n",
      "Epoch 49/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6728 - val_loss: 0.6700\n",
      "Epoch 50/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6728 - val_loss: 0.6700\n",
      "Epoch 51/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6728 - val_loss: 0.6701\n",
      "Epoch 52/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6727 - val_loss: 0.6700\n",
      "Epoch 53/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6727 - val_loss: 0.6700\n",
      "Epoch 54/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6727 - val_loss: 0.6699\n",
      "Epoch 55/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6727 - val_loss: 0.6699\n",
      "Epoch 56/100\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.6726 - val_loss: 0.6699\n",
      "Epoch 57/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6726 - val_loss: 0.6700\n",
      "Epoch 58/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6726 - val_loss: 0.6698\n",
      "Epoch 59/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6726 - val_loss: 0.6698\n",
      "Epoch 60/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6725 - val_loss: 0.6699\n",
      "Epoch 61/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6725 - val_loss: 0.6698\n",
      "Epoch 62/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6725 - val_loss: 0.6699\n",
      "Epoch 63/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6725 - val_loss: 0.6697\n",
      "Epoch 64/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6725 - val_loss: 0.6696\n",
      "Epoch 65/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6724 - val_loss: 0.6698\n",
      "Epoch 66/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6724 - val_loss: 0.6697\n",
      "Epoch 67/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6724 - val_loss: 0.6697\n",
      "Epoch 68/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6724 - val_loss: 0.6697\n",
      "Epoch 69/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6724 - val_loss: 0.6696\n",
      "Epoch 70/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6723 - val_loss: 0.6696\n",
      "Epoch 71/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6723 - val_loss: 0.6695\n",
      "Epoch 72/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6723 - val_loss: 0.6695\n",
      "Epoch 73/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6723 - val_loss: 0.6695\n",
      "Epoch 74/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6723 - val_loss: 0.6695\n",
      "Epoch 75/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6722 - val_loss: 0.6695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6722 - val_loss: 0.6695\n",
      "Epoch 77/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6722 - val_loss: 0.6694\n",
      "Epoch 78/100\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.6721 - val_loss: 0.6694\n",
      "Epoch 79/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6721 - val_loss: 0.6695\n",
      "Epoch 80/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6721 - val_loss: 0.6694\n",
      "Epoch 81/100\n",
      "54000/54000 [==============================] - 3s 65us/sample - loss: 0.6720 - val_loss: 0.6693\n",
      "Epoch 82/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6720 - val_loss: 0.6693\n",
      "Epoch 83/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6719 - val_loss: 0.6692\n",
      "Epoch 84/100\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6719 - val_loss: 0.6692\n",
      "Epoch 85/100\n",
      "54000/54000 [==============================] - 3s 63us/sample - loss: 0.6719 - val_loss: 0.6692\n",
      "Epoch 86/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6718 - val_loss: 0.6691\n",
      "Epoch 87/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6718 - val_loss: 0.6691\n",
      "Epoch 88/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6718 - val_loss: 0.6692\n",
      "Epoch 89/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6718 - val_loss: 0.6692\n",
      "Epoch 90/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6717 - val_loss: 0.6690\n",
      "Epoch 91/100\n",
      "54000/54000 [==============================] - 3s 65us/sample - loss: 0.6717 - val_loss: 0.6690\n",
      "Epoch 92/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6717 - val_loss: 0.6689\n",
      "Epoch 93/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6717 - val_loss: 0.6689\n",
      "Epoch 94/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6716 - val_loss: 0.6689\n",
      "Epoch 95/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6716 - val_loss: 0.6690\n",
      "Epoch 96/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6716 - val_loss: 0.6688\n",
      "Epoch 97/100\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.6715 - val_loss: 0.6688\n",
      "Epoch 98/100\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.6715 - val_loss: 0.6688\n",
      "Epoch 99/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6715 - val_loss: 0.6687\n",
      "Epoch 100/100\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.6714 - val_loss: 0.6687\n",
      "CPU times: user 5min 24s, sys: 17.1 s, total: 5min 41s\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = auto_encoder.fit(x_train, x_train, batch_size=64, epochs=100, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded = encoder.predict(x_test)\n",
    "decoded = decoder.predict(encoded)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(2, n, n+i+1)\n",
    "    plt.imshow(decoded[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
