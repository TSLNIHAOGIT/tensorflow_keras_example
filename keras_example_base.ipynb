{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最常见的模型类型是层的堆叠：tf.keras.Sequential 模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f2e09ce86a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2.2网络配置\n",
    "tf.keras.layers中网络配置：\n",
    "\n",
    "activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "\n",
    "kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 “Glorot uniform” 初始化器。\n",
    "\n",
    "kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\n",
    "'''\n",
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.训练和评估\n",
    "3.1设置训练流程\n",
    "构建好模型后，通过调用 compile 方法配置该模型的学习流程：\n",
    "'''\n",
    "##可以model.add()添加层，也可以直接将列表加进去\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              ##上面的优化函数才是对的，tf.train.AdamOptimizer不能用\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  optimizer=tf.optimizers.Adam(0.001)\n",
    "#  optimizer2=tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "#两个来源一样都是keras.adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),#tf.train.RMSPropOptimizer(0.01)不能用\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 08:06:48.920107 140578539656960 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 554us/sample - loss: 11.6933 - accuracy: 0.1030 - val_loss: 11.7745 - val_accuracy: 0.1200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 11.6446 - accuracy: 0.1180 - val_loss: 11.7627 - val_accuracy: 0.0650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 11.6303 - accuracy: 0.1190 - val_loss: 11.7594 - val_accuracy: 0.0600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 11.6226 - accuracy: 0.1070 - val_loss: 11.7585 - val_accuracy: 0.0750\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 11.6170 - accuracy: 0.1270 - val_loss: 11.7570 - val_accuracy: 0.0950\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 11.6127 - accuracy: 0.1270 - val_loss: 11.7562 - val_accuracy: 0.0600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 11.6084 - accuracy: 0.1320 - val_loss: 11.7576 - val_accuracy: 0.0800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 11.6043 - accuracy: 0.1370 - val_loss: 11.7567 - val_accuracy: 0.0850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 11.6001 - accuracy: 0.1420 - val_loss: 11.7576 - val_accuracy: 0.0750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 11.5963 - accuracy: 0.1480 - val_loss: 11.7558 - val_accuracy: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdaf43edf28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.2输入Numpy数据\n",
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))\n",
    "\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 08:07:39.601559 140578539656960 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 11.6008 - accuracy: 0.1469 - val_loss: 11.9940 - val_accuracy: 0.0833\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 11.5828 - accuracy: 0.1389 - val_loss: 11.9843 - val_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5938 - accuracy: 0.1538 - val_loss: 11.9902 - val_accuracy: 0.0833\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.6045 - accuracy: 0.1688 - val_loss: 11.9958 - val_accuracy: 0.0729\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5691 - accuracy: 0.1859 - val_loss: 12.0027 - val_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5686 - accuracy: 0.1891 - val_loss: 12.0048 - val_accuracy: 0.1146\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5349 - accuracy: 0.1976 - val_loss: 12.0074 - val_accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5540 - accuracy: 0.2019 - val_loss: 12.0095 - val_accuracy: 0.1250\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5269 - accuracy: 0.1880 - val_loss: 12.0123 - val_accuracy: 0.1042\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5432 - accuracy: 0.2019 - val_loss: 12.0125 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda868314a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.3tf.data输入数据\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset, validation_steps=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 68us/sample - loss: 11.5723 - categorical_accuracy: 0.1140\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5784 - categorical_accuracy: 0.1146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.57843910853068, 0.114583336]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.4评估与预测\n",
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 08:55:04.768955 140074130970368 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.5401 - categorical_accuracy: 0.1208\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5336 - categorical_accuracy: 0.0972\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5608 - categorical_accuracy: 0.1090\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5334 - categorical_accuracy: 0.1132\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5519 - categorical_accuracy: 0.1068\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5244 - categorical_accuracy: 0.1239\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5345 - categorical_accuracy: 0.1036\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5216 - categorical_accuracy: 0.1314\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5612 - categorical_accuracy: 0.1197\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.5247 - categorical_accuracy: 0.1036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f650e454978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''输入 tf.data 数据集\n",
    "使用 Datasets API 可扩展为大型数据集或多设备训练。\n",
    "将 tf.data.Dataset 实例传递到 fit 方法：'''\n",
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11008526 0.09580339 0.09877068 ... 0.10400292 0.10196316 0.09956846]\n",
      " [0.10401383 0.09606762 0.1050818  ... 0.10323157 0.09778462 0.09813404]\n",
      " [0.10338207 0.09573887 0.10557301 ... 0.10309436 0.09741373 0.09807102]\n",
      " ...\n",
      " [0.10336718 0.09577353 0.10557701 ... 0.10310866 0.09741092 0.09813978]\n",
      " [0.10907789 0.0865532  0.09761617 ... 0.0987197  0.11294651 0.10839939]\n",
      " [0.10457279 0.09494692 0.1042695  ... 0.10273406 0.09940954 0.09927887]]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 430us/sample - loss: 11.6284 - accuracy: 0.0990\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 174us/sample - loss: 11.5598 - accuracy: 0.1050\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 180us/sample - loss: 11.5571 - accuracy: 0.1040\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 187us/sample - loss: 11.5562 - accuracy: 0.1020\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 164us/sample - loss: 11.5557 - accuracy: 0.1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f65158ecc18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.构建高级模型\n",
    "4.1函数式api\n",
    "tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "多输入模型，\n",
    "\n",
    "多输出模型，\n",
    "\n",
    "具有共享层的模型（同一层被调用多次），\n",
    "\n",
    "具有非序列数据流的模型（例如，残差连接）。\n",
    "\n",
    "\n",
    "使用函数式 API 构建的模型具有以下特征：\n",
    "\n",
    "层实例可调用并返回张量。\n",
    "输入张量和输出张量用于定义 tf.keras.Model 实例。\n",
    "此模型的训练方式和 Sequential 模型一样。\n",
    "\n",
    "##tf.keras.Input中shape表示去掉batch_size之后的维度；\n",
    "train_x=（1000,72）\n",
    "'''\n",
    "input_x = tf.keras.Input(shape=(72,))\n",
    "hidden1 = layers.Dense(32, activation='relu')(input_x)\n",
    "hidden2 = layers.Dense(16, activation='relu')(hidden1)\n",
    "pred = layers.Dense(10, activation='softmax')(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=pred)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 72)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 11.7061 - accuracy: 0.1190\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 334us/sample - loss: 11.6337 - accuracy: 0.1220\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 329us/sample - loss: 11.6060 - accuracy: 0.1170\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 315us/sample - loss: 11.5845 - accuracy: 0.1170\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 284us/sample - loss: 11.5724 - accuracy: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f64a86369b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.2模型子类化\n",
    "通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。\n",
    "在 init 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播\n",
    "'''\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    #在 init 方法中创建层并将它们设置为类实例的属性\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = layers.Dense(32, activation='relu')\n",
    "        self.layer2 = layers.Dense(num_classes, activation='softmax')\n",
    "    #在 call 方法中定义前向传播\n",
    "    def call(self, inputs):\n",
    "        h1 = self.layer1(inputs)\n",
    "        out = self.layer2(h1)\n",
    "        return out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShapej(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 397us/sample - loss: 11.5760 - accuracy: 0.0750\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 271us/sample - loss: 11.5662 - accuracy: 0.0890\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 264us/sample - loss: 11.5582 - accuracy: 0.1240\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 260us/sample - loss: 11.5534 - accuracy: 0.1060\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 259us/sample - loss: 11.5493 - accuracy: 0.1240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6484037f60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.3自定义层\n",
    "通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：\n",
    "使用 add_weight 方法添加权重。\n",
    "\n",
    "\n",
    "'''\n",
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    \n",
    "\n",
    "    #build：创建层的权重。##不知道输入的维度重新build函数\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel1', shape=shape,\n",
    "                                   initializer='uniform', trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "    #call：定义前向传播。将输入和该层的权重联系起来（相乘）\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    #compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。\n",
    "    #或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    MyLayer(10),\n",
    "    layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当定义网络时不知道网络的维度是可以重写build()函数，用获得的shape构建网络\n",
    "class MyLayer(layers.Layer):##初始化时不知道输入的维度，此时要重写build函数，自己添加输入的维度\n",
    "    def __init__(self, unit=32):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.unit = unit\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(shape=(input_shape[-1], self.unit),\n",
    "                                     initializer=keras.initializers.RandomNormal(),\n",
    "                                     trainable=True)\n",
    "        self.bias = self.add_weight(shape=(self.unit,),\n",
    "                                   initializer=keras.initializers.Zeros(),\n",
    "                                   trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias\n",
    "        \n",
    "\n",
    "my_layer = MyLayer(3)\n",
    "x = tf.ones((3,5))\n",
    "out = my_layer(x)\n",
    "print(out)\n",
    "my_layer = MyLayer(3)\n",
    "\n",
    "x = tf.ones((2,2))\n",
    "out = my_layer(x)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络层就是：设置网络权重和输出到输入的计算过程\n",
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, input_dim=32, unit=32):\n",
    "        super(MyLayer, self).__init__()\n",
    "        \n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.weight = tf.Variable(initial_value=w_init(\n",
    "            shape=(input_dim, unit), dtype=tf.float32), trainable=True)\n",
    "        \n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.bias = tf.Variable(initial_value=b_init(\n",
    "            shape=(unit,), dtype=tf.float32), trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias\n",
    "        \n",
    "x = tf.ones((3,5))\n",
    "my_layer = MyLayer(5, 4)\n",
    "out = my_layer(x)\n",
    "print(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按上面构建网络层，图层会自动跟踪权重w和b，当然我们也可以直接用add_weight的方法构建权重\n",
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, input_dim=32, unit=32):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.weight = self.add_weight(shape=(input_dim, unit),\n",
    "                                     initializer=keras.initializers.RandomNormal(),\n",
    "                                     trainable=True)\n",
    "        self.bias = self.add_weight(shape=(unit,),\n",
    "                                   initializer=keras.initializers.Zeros(),\n",
    "                                   trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias\n",
    "        \n",
    "x = tf.ones((3,5))\n",
    "my_layer = MyLayer(5, 4)\n",
    "out = my_layer(x)\n",
    "print(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#也可以设置不可训练的权重\n",
    "class AddLayer(layers.Layer):\n",
    "    def __init__(self, input_dim=32):\n",
    "        super(AddLayer, self).__init__()\n",
    "        self.sum = self.add_weight(shape=(input_dim,),\n",
    "                                     initializer=keras.initializers.Zeros(),\n",
    "                                     trainable=False)##权重不可训练\n",
    "       \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.sum.assign_add(tf.reduce_sum(inputs, axis=0))\n",
    "        return self.sum\n",
    "        \n",
    "x = tf.ones((3,3))\n",
    "my_layer = AddLayer(3)\n",
    "out = my_layer(x)\n",
    "print(out.numpy())\n",
    "out = my_layer(x)\n",
    "print(out.numpy())\n",
    "print('weight:', my_layer.weights)\n",
    "print('non-trainable weight:', my_layer.non_trainable_weights)\n",
    "print('trainable weight:', my_layer.trainable_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 09:12:06.597361 140074130970368 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.198192). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  16/1000 [..............................] - ETA: 12s - loss: 11.7791 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 09:12:06.621986 140074130970368 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.106626). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 616us/sample - loss: 11.5448 - accuracy: 0.1310 - val_loss: 11.5356 - val_accuracy: 0.0800\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 310us/sample - loss: 11.5424 - accuracy: 0.1420 - val_loss: 11.5215 - val_accuracy: 0.0650\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 275us/sample - loss: 11.5392 - accuracy: 0.1380 - val_loss: 11.5229 - val_accuracy: 0.0700\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 285us/sample - loss: 11.5361 - accuracy: 0.1280 - val_loss: 11.5319 - val_accuracy: 0.0700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f64a85bff28>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.3回调\n",
    "\n",
    "##在fit参数上添加\n",
    "##回调有验证集的early stopping,以及日志的保存\n",
    "# monitor: 需要监视的量，val_loss，val_acc\n",
    "# patience: 当验证集上的性能不再提高时，终止训练。当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
    "# verbose: 信息展示模式\n",
    "# mode: 'auto','min','max'之一，在min模式训练，如果检测值停止下降则终止训练。在max模式下，当检测值不再上升的时候则停止训练。\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5,\n",
    "         callbacks=callbacks, validation_data=(val_x, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 554us/sample - loss: 11.6760 - accuracy: 0.0970\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 348us/sample - loss: 11.6054 - accuracy: 0.1070\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 338us/sample - loss: 11.5820 - accuracy: 0.1160\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 311us/sample - loss: 11.5659 - accuracy: 0.1120\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 368us/sample - loss: 11.5547 - accuracy: 0.1210\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5保持和恢复\n",
    "5.1权重保存\n",
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#训练完模型后才有权重可以保存\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)\n",
    "model.save_weights('./weights/model')\n",
    "model.load_weights('./weights/model')\n",
    "model.save_weights('./model.h5')\n",
    "model.load_weights('./model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  model.data-00000-of-00002  model.data-00001-of-00002  model.index\r\n"
     ]
    }
   ],
   "source": [
    "ls weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'build_input_shape': [None, 72],\n",
      "            'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_26',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_27',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_8'},\n",
      " 'keras_version': '2.2.4-tf'}\n"
     ]
    }
   ],
   "source": [
    "#5.2保存网络结构\n",
    "# 序列化成json\n",
    "import json\n",
    "import pprint\n",
    "json_str = model.to_json()\n",
    "pprint.pprint(json.loads(json_str))\n",
    "fresh_model = tf.keras.models.model_from_json(json_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  build_input_shape: !!python/tuple\n",
      "  - null\n",
      "  - 72\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_26\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_27\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_8\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/saving/model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "# 保持为yaml格式  #需要提前安装pyyaml\n",
    "\n",
    "yaml_str = model.to_yaml()\n",
    "print(yaml_str)\n",
    "fresh_model = tf.keras.models.model_from_yaml(yaml_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 426us/sample - loss: 11.5665 - accuracy: 0.0870\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 193us/sample - loss: 11.5587 - accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 202us/sample - loss: 11.5573 - accuracy: 0.1070\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 206us/sample - loss: 11.5567 - accuracy: 0.0940\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 193us/sample - loss: 11.5560 - accuracy: 0.1090\n"
     ]
    }
   ],
   "source": [
    "#5.3保存整个模型\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(72,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "model.save('all_model.h5')\n",
    "model = tf.keras.models.load_model('all_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_model.h5               \u001b[0m\u001b[01;34mlogs\u001b[0m/                         \u001b[01;34mweights\u001b[0m/\r\n",
      "keras_example.ipynb        model.h5\r\n",
      "keras_example_beta1.ipynb  tensorflow_2_0_example.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 09:24:12.507230 140074130970368 estimator.py:1811] Using temporary folder as model directory: /tmp/tmppop698bv\n"
     ]
    }
   ],
   "source": [
    "# 6.将keras用于Estimator\n",
    "# Estimator API 用于针对分布式环境训练模型。\n",
    "# 它适用于一些行业使用场景，例如用大型数据集进行分布式训练并导出模型以用于生产\n",
    "model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\n",
    "                          layers.Dense(10,activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
