{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n",
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2])\n",
    "b = tf.constant([3, 4])\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f00177690b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0705 04:39:15.867008 139640494470912 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 575us/sample - loss: 11.6090 - categorical_accuracy: 0.0920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 11.5466 - categorical_accuracy: 0.0960\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 11.5439 - categorical_accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 11.5450 - categorical_accuracy: 0.1070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 155us/sample - loss: 11.5435 - categorical_accuracy: 0.1040\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 155us/sample - loss: 11.5431 - categorical_accuracy: 0.1060\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 157us/sample - loss: 11.5382 - categorical_accuracy: 0.1270\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 183us/sample - loss: 11.5354 - categorical_accuracy: 0.1190\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 181us/sample - loss: 11.5325 - categorical_accuracy: 0.1370\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 175us/sample - loss: 11.5323 - categorical_accuracy: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f002534ccf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 268us/sample - loss: 11.5192 - categorical_accuracy: 0.1110 - val_loss: 11.5117 - val_categorical_accuracy: 0.0500\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 11.5173 - categorical_accuracy: 0.1090 - val_loss: 11.5173 - val_categorical_accuracy: 0.1800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 11.5176 - categorical_accuracy: 0.1130 - val_loss: 11.5124 - val_categorical_accuracy: 0.0800\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 11.5167 - categorical_accuracy: 0.1030 - val_loss: 11.5112 - val_categorical_accuracy: 0.0600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 11.5180 - categorical_accuracy: 0.1020 - val_loss: 11.5073 - val_categorical_accuracy: 0.1100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 168us/sample - loss: 11.5164 - categorical_accuracy: 0.1030 - val_loss: 11.5095 - val_categorical_accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 167us/sample - loss: 11.5170 - categorical_accuracy: 0.1020 - val_loss: 11.5164 - val_categorical_accuracy: 0.0800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 171us/sample - loss: 11.5158 - categorical_accuracy: 0.0990 - val_loss: 11.5143 - val_categorical_accuracy: 0.1300\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 192us/sample - loss: 11.5151 - categorical_accuracy: 0.1160 - val_loss: 11.5945 - val_categorical_accuracy: 0.1100\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 189us/sample - loss: 11.5137 - categorical_accuracy: 0.0930 - val_loss: 11.5176 - val_categorical_accuracy: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f008c5b32b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
