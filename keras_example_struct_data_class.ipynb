{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本教程展示了如何对结构化数据进行分类（例如CSV中的表格数据）。我们使用Keras定义模型，并将csv中各列的特征转化为训练的输入。 本教程包含一下功能代码：\n",
    "\n",
    "# 使用Pandas加载CSV文件。\n",
    "# 构建一个输入的pipeline，使用tf.data批处理和打乱数据。\n",
    "# 从CSV中的列映射到用于训练模型的输入要素。\n",
    "# 使用Keras构建，训练和评估模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置为训练阶段，测试时要改变一下状态\n",
    "# tf.keras.backend.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.数据集\n",
    "# 我们将使用克利夫兰诊所心脏病基金会提供的一个小数据集。 CSV中有几百行。 每行描述一个患者，每列描述一个属性。 我们将使用此信息来预测患者是否患有心脏病，该疾病在该数据集中是二元分类任务。\n",
    "\n",
    "# Column\tDescription\tFeature Type\tData Type\n",
    "# Age\tAge in years\tNumerical\tinteger\n",
    "# Sex\t(1 = male; 0 = female)\tCategorical\tinteger\n",
    "# CP\tChest pain type (0, 1, 2, 3, 4)\tCategorical\tinteger\n",
    "# Trestbpd\tResting blood pressure (in mm Hg on admission to the hospital)\tNumerical\tinteger\n",
    "# Chol\tSerum cholestoral in mg/dl\tNumerical\tinteger\n",
    "# FBS\t(fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\tCategorical\tinteger\n",
    "# RestECG\tResting electrocardiographic results (0, 1, 2)\tCategorical\tinteger\n",
    "# Thalach\tMaximum heart rate achieved\tNumerical\tinteger\n",
    "# Exang\tExercise induced angina (1 = yes; 0 = no)\tCategorical\tinteger\n",
    "# Oldpeak\tST depression induced by exercise relative to rest\tNumerical\tinteger\n",
    "# Slope\tThe slope of the peak exercise ST segment\tNumerical\tfloat\n",
    "# CA\tNumber of major vessels (0-3) colored by flourosopy\tNumerical\tinteger\n",
    "# Thal\t3 = normal; 6 = fixed defect; 7 = reversable defect\tCategorical\tstring\n",
    "# Target\tDiagnosis of heart disease (1 = true; 0 = false)\tClassification\tinteger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.准备数据\n",
    "# 使用pandas读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "dataframe = pd.read_csv('heart.csv')\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 train examples\n",
      "49 validation examples\n",
      "61 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf.data构造输入pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('target')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['sex', 'ca', 'restecg', 'fbs', 'slope', 'age', 'thal', 'trestbps', 'oldpeak', 'cp', 'thalach', 'exang', 'chol']\n",
      "A batch of ages: tf.Tensor([51 44 54 50 63], shape=(5,), dtype=int32)\n",
      "A batch of targets: tf.Tensor([0 0 0 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    print('A batch of ages:', feature_batch['age'])\n",
    "    print('A batch of targets:', label_batch )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.tensorflow的feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(train_ds))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(feature_column):\n",
    "    feature_layer = layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字列\n",
    "# 特征列的输出成为模型的输入。 数字列是最简单的列类型。\n",
    "# 它用于表示真正有价值的特征。 使用此列时，模型将从数据框中接收未更改的列值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51.]\n",
      " [44.]\n",
      " [54.]\n",
      " [50.]\n",
      " [63.]]\n"
     ]
    }
   ],
   "source": [
    "age = feature_column.numeric_column(\"age\")\n",
    "demo(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Bucketized列（桶列）\n",
    "# 通常，您不希望将数字直接输入模型，而是根据数值范围将其值分成不同的类别。 考虑代表一个人年龄的原始数据。 我们可以使用bucketized列将年龄分成几个桶，而不是将年龄表示为数字列。\n",
    "# 请注意，下面的one-hot描述了每行匹配的年龄范围\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[\n",
    "    18, 25, 30, 35, 40, 50\n",
    "])\n",
    "demo(age_buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别列\n",
    "# 在该数据集中，thal表示为字符串（例如“固定”，“正常”或“可逆”）。 \n",
    "# 我们无法直接将字符串提供给模型。 相反，我们必须首先将它们映射到数值。\n",
    "# 类别列提供了一种将字符串表示为单热矢量的方法（就像上面用年龄段看到的那样）。\n",
    "# 类别表可以使用categorical_column_with_vocabulary_list作为列表传递，\n",
    "# 或者使用categorical_column_with_vocabulary_file从文件加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 08:43:31.174859 140256506197760 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0717 08:43:31.195041 140256506197760 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0717 08:43:31.196534 140256506197760 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "thal = feature_column.categorical_column_with_vocabulary_list('thal', ['fixed', 'normal', 'reversible'])\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "demo(thal_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3620166  -0.6456163   0.00524763 -0.10068625  0.09312668 -0.46276256\n",
      "   0.00324896 -0.6430978 ]\n",
      " [-0.3620166  -0.6456163   0.00524763 -0.10068625  0.09312668 -0.46276256\n",
      "   0.00324896 -0.6430978 ]\n",
      " [-0.4823083   0.52749336  0.1720718  -0.4150295   0.25318253  0.35226077\n",
      "  -0.57979906 -0.13844857]\n",
      " [-0.4823083   0.52749336  0.1720718  -0.4150295   0.25318253  0.35226077\n",
      "  -0.57979906 -0.13844857]\n",
      " [-0.4823083   0.52749336  0.1720718  -0.4150295   0.25318253  0.35226077\n",
      "  -0.57979906 -0.13844857]]\n"
     ]
    }
   ],
   "source": [
    "# 嵌入列\n",
    "# 假设我们不是只有几个可能的字符串，而是每个类别有数千（或更多）值。\n",
    "# 由于多种原因，随着类别数量的增加，使用单热编码训练神经网络变得不可行。 \n",
    "# 我们可以使用嵌入列来克服此限制。\n",
    "# 嵌入列不是将数据表示为多维度的单热矢量，而是将数据表示为低维密集向量，\n",
    "# 其中每个单元格可以包含任意数字，而不仅仅是0或1.嵌入的大小是必须训练调整的参数。\n",
    "\n",
    "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "demo(thal_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 哈希特征列\n",
    "# 表示具有大量值的分类列的另一种方法是使用categorical_column_with_hash_bucket。\n",
    "# 此功能列计算输入的哈希值，然后选择一个hash_bucket_size存储桶来编码字符串。\n",
    "# 使用此列时，您不需要提供词汇表，\n",
    "# 并且可以选择使hash_buckets的数量远远小于实际类别的数量以节省空间。\n",
    "\n",
    "# 注：该技术的一个重要缺点是可能存在冲突，其中不同的字符串被映射到同一个桶。\n",
    "# --------------------- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 08:43:31.808743 140256506197760 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "thal_hashed = feature_column.categorical_column_with_hash_bucket('thal', hash_bucket_size=1000)\n",
    "demo(feature_column.indicator_column(thal_hashed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉功能列\n",
    "# 将特征组合成单个特征（更好地称为特征交叉），使模型能够为每个特征组合学习单独的权重。 \n",
    "# 在这里，我们将创建一个与age和thal交叉的新功能。 \n",
    "# 请注意，crossed_column不会构建所有可能组合的完整表（可能非常大）。 \n",
    "# 相反，它由hashed_column支持，因此您可以选择表的大小。\n",
    "# --------------------- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 08:43:32.479847 140256506197760 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
    "demo(feature_column.indicator_column(crossed_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.选择使用feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# bucketized cols\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# indicator cols\n",
    "thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "      'thal', ['fixed', 'normal', 'reversible'])\n",
    "thal_one_hot = feature_column.indicator_column(thal)\n",
    "feature_columns.append(thal_one_hot)\n",
    "\n",
    "# embedding cols\n",
    "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "feature_columns.append(thal_embedding)\n",
    "\n",
    "# crossed cols\n",
    "crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
    "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
    "feature_columns.append(crossed_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建特征层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.feature_column.feature_column_v2.DenseFeatures at 0x7f8edf0b67f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.构建模型并训练\n",
    "# layers.Dense(128, activation='relu'),\n",
    "# layers.Dropout(0.5),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "trainable weights: 4\n"
     ]
    }
   ],
   "source": [
    "# # 配置只有训练时可以执行的网络层\n",
    "class MyDropout(layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(MyDropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "    def call(self, inputs, training=None):\n",
    "        return tf.cond(training, \n",
    "                       lambda: tf.nn.dropout(inputs, rate=self.rate),\n",
    "                      lambda: inputs)\n",
    "\n",
    "#2.使用子层递归构建网络层\n",
    "class MyBlock_dense_norm_relu_drop_relu(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyBlock_dense_norm_relu_drop_relu, self).__init__()\n",
    "        self.dense = layers.Dense(128)\n",
    "        self.batch_norm=layers.BatchNormalization()\n",
    "#         self.drop_out=layers.Dropout(0.5)\n",
    "        self.drop_out=MyDropout(0.5)\n",
    "        self.reul_func1=layers.Activation('relu')\n",
    "        self.reul_func2=layers.Activation('relu')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h1 = self.dense(inputs)\n",
    "        h1 = self.batch_norm(h1) \n",
    "#         h1 = tf.nn.relu(h1)\n",
    "        h1=  self.reul_func1(h1)\n",
    "        h1=self.drop_out(h1)\n",
    "#         h1 = tf.nn.relu(h1)\n",
    "        h1=  self.reul_func2(h1)\n",
    "        return h1\n",
    "    \n",
    "my_block = MyBlock_dense_norm_relu_drop_relu()\n",
    "print('trainable weights:', len(my_block.trainable_weights))\n",
    "y = my_block(tf.ones(shape=(3, 64)))\n",
    "# 构建网络在build()里面，所以执行了才有网络\n",
    "print('trainable weights:', len(my_block.trainable_weights)) \n",
    "# print(my_block.losses) \n",
    "# print(my_block.weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义dense->batchnorm->relu->dropout->relu block结构\n",
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    MyBlock_dense_norm_relu_drop_relu(),\n",
    "\n",
    "    MyBlock_dense_norm_relu_drop_relu(),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##原始\n",
    "# model = tf.keras.Sequential([\n",
    "#     feature_layer,\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "# #     layers.BatchNormalization(),\n",
    "# #     layers.Dropout(0.2),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "# #     layers.BatchNormalization(),\n",
    "# #     layers.Dropout(0.2),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##自己加了batchnorm和dropout\n",
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "             optimizer='adam',\n",
    "#              optimizer=keras.optimizers.SGD(),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'],\n",
    "             run_eagerly=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 492ms/step - loss: 0.8275 - accuracy: 0.5260 - val_loss: 0.8682 - val_accuracy: 0.7551\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.7890 - accuracy: 0.5650 - val_loss: 1.0517 - val_accuracy: 0.7551\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.8104 - accuracy: 0.5868 - val_loss: 0.7472 - val_accuracy: 0.7551\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.7800 - accuracy: 0.6336 - val_loss: 0.6507 - val_accuracy: 0.7551\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.6787 - accuracy: 0.6632 - val_loss: 0.7015 - val_accuracy: 0.7551\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.6581 - accuracy: 0.6600 - val_loss: 0.7329 - val_accuracy: 0.7551\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.7164 - accuracy: 0.6382 - val_loss: 0.8159 - val_accuracy: 0.7551\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.6370 - accuracy: 0.7209 - val_loss: 0.7933 - val_accuracy: 0.7551\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.6885 - accuracy: 0.7006 - val_loss: 0.8301 - val_accuracy: 0.7551\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.6247 - accuracy: 0.7303 - val_loss: 0.8871 - val_accuracy: 0.7551\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.7297 - accuracy: 0.6008 - val_loss: 1.1194 - val_accuracy: 0.7551\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.6080 - accuracy: 0.7303 - val_loss: 1.2216 - val_accuracy: 0.7551\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.5503 - accuracy: 0.7552 - val_loss: 1.2460 - val_accuracy: 0.7551\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.6526 - accuracy: 0.6882 - val_loss: 1.1208 - val_accuracy: 0.7551\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.5849 - accuracy: 0.6881 - val_loss: 0.8505 - val_accuracy: 0.7551\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.6599 - accuracy: 0.6788 - val_loss: 0.6711 - val_accuracy: 0.7551\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.5434 - accuracy: 0.7100 - val_loss: 0.5207 - val_accuracy: 0.8367\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.5154 - accuracy: 0.7505 - val_loss: 0.4782 - val_accuracy: 0.8367\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.5552 - accuracy: 0.7380 - val_loss: 0.5473 - val_accuracy: 0.7959\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 0.5075 - accuracy: 0.7287 - val_loss: 0.6124 - val_accuracy: 0.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8edf0b6e48>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds,epochs=20)##不关变量，似乎都是在上一次的基础上继续训练的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5787 - accuracy: 0.7705\n",
      "Accuracy 0.7704918\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
