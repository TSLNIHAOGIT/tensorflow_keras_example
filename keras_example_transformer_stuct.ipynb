{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d359c8a375304c5287bfa760033dc7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Completed...', max=1, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d119dbd2e1ac48b7a4ad82b7305f1c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Size...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44af86740f64b7aab86b16718c52298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Extraction completed...', max=1, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a start and end token to the input and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 00:59:05.314560 139772362209024 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0725 00:59:05.316391 139772362209024 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0725 00:59:05.318343 139772345423616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0725 00:59:05.319373 139772345423616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0725 00:59:05.324951 139772362209024 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=311074, shape=(16, 30), dtype=int64, numpy=\n",
       " array([[8214, 1259,    5,   63, 5284,   50,  277,    2, 8215,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,  299,   13,  803, 6422,   33, 5306,   40, 1236,   17, 4347,\n",
       "         1189,   17, 1784, 1412, 7144,  829, 8215,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   59,    8,    7,  270,  884,    5,   27, 1700,    2, 8215,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   25,  533,   13,    7,  757, 7009,    2, 8215,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   34,   66,    5, 1316,  984,    6,   21, 3563,   20,  331,\n",
       "         3655,   17, 7414,   81,    2, 8215,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,    5,    7,    3,    8,    9,    7,    3,  501, 8063, 6120,\n",
       "         3585,    1, 4043,  132,    5,    3, 6492,    8,    9,  643,   14,\n",
       "          598, 1776,    2, 8215,    0,    0,    0,    0],\n",
       "        [8214,    6,   46,  198,  217, 5122,   24,  627,    4, 1890,    2,\n",
       "         8215,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   27,  227,    9,   36,  162, 4281,   12,    4, 3209,    2,\n",
       "         8215,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,    6,    7, 1001,    6, 1802, 8003,   16,   33, 6850, 7990,\n",
       "           20,    7, 3576,   14,    5,   95,    3, 1334,    2, 8215,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   62,    5, 2373, 2385,   24, 2317,    2, 8215,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,    8,   84,    5,   27, 3045,   28,   27, 5590,   22, 4573,\n",
       "            1,  117, 1163, 1978,   15, 2469, 2675,    4,  367, 1696,  735,\n",
       "            2, 8215,    0,    0,    0,    0,    0,    0],\n",
       "        [8214, 3401, 3257,  135, 1029,    2, 8215,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,   12,  172, 1904,   34,  579,   15,    5,  287,  134,  862,\n",
       "         8067,    1, 3675,   17,  135, 2216,   11,    3, 1942, 4887,    1,\n",
       "           10, 5448,    3, 2043,    4, 5714,    2, 8215],\n",
       "        [8214, 7618, 7990,   12, 6166,   17,  937,    9, 1740, 3996,    2,\n",
       "         8215,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214, 1023,  131, 1335, 1948, 7006,  157, 8215,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8214,    6,    3,  521, 3044,   15, 1548,    8, 5486,    2, 8215,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])>,\n",
       " <tf.Tensor: id=311075, shape=(16, 27), dtype=int64, numpy=\n",
       " array([[8087,   18,   12,  631,   15,   31,  272,    2, 8088,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,  634,   30, 7941, 7870,   26,  107,  303,  144, 3201,   59,\n",
       "           51,    8,   41, 3235,   48,    3, 2674,  830, 7942, 7876, 2954,\n",
       "         7863, 1501, 4342, 5218, 8088],\n",
       "        [8087,   16,   13,    3,  124,  774,   10,   12,  276, 2224,    2,\n",
       "         8088,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   15,  381, 1066, 7941, 7870, 7947,    2, 8088,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   25,   22,    3,  835,   10,  170, 1219, 3526, 7863,   37,\n",
       "            7, 2452,   21, 4094, 4005, 7946,    2, 8088,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   10,    7,   13,    7, 2383, 7928,    1, 6537, 7863,   10,\n",
       "         2320, 1202, 2785,   13,   45,  299,   11,  922,    2, 8088,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,    4,   64,   22,  260,   89, 4536,   11,    3, 4707,    2,\n",
       "         8088,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   12,  313,   47,    6,  176, 1458, 3017, 2893, 7946,    2,\n",
       "         8088,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,    4, 5123, 7863,   20,   68, 5796,   35,    3, 1701,   10,\n",
       "           65,   20,  347,  152,    2, 8088,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   15,   24,    5, 1398,    5,  300,   11, 1236,    2, 8088,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   16,   13,   95,   12, 1605,   52,   12,  271,   11, 5121,\n",
       "            1,   38,    3, 1141, 1187,    6,    3, 3204, 1811,   12,  879,\n",
       "         1490,    2, 8088,    0,    0],\n",
       "        [8087,   12, 5453,    5,   34, 2860,  125,    2, 8088,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   43, 2996,   22,    3,  332,  105,    8,   74,  276, 6850,\n",
       "            1, 2699,   60,  549,   21, 6534,    1,   45, 4534, 7863,  133,\n",
       "         7414,    6, 2179,    2, 8088],\n",
       "        [8087,   12, 1215, 2993, 7863,    3, 6175, 7863,   11,    7, 1012,\n",
       "         6107,    2, 8088,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,   12,   20,   18, 3668,   10,    7, 2327, 3672, 7863, 1146,\n",
       "           49,  498,    5, 1353,    2, 8088,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [8087,    4,    3,  483,   97,    6,    3, 1436,  306,   13, 7315,\n",
       "          117,    2, 8088,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  sines = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  cosines = np.cos(angle_rads[:, 1::2])\n",
    "  \n",
    "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "  \n",
    "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking\n",
    "# Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions so that we can add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=311091, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "# This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3) tf.Tensor([[0.13045144 0.09085131 0.25443566]], shape=(1, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=311133, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "print(x.shape,x)\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer\n",
    "# Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep this example small and relatively fast, the values for num_layers, d_model, and dff have been reduced.\n",
    "\n",
    "# The values used in the base model of transformer were; num_layers=6, d_model = 512, dff = 2048. See the paper for all the other versions of the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# Use the Adam optimizer with a custom learning rate scheduler according to the formula in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and metrics\n",
    "# # Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every n epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. tar_real is that same input shifted by 1: At each location in tar_input, tar_real contains the next token that should be predicted.\n",
    "\n",
    "# For example, sentence = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "# tar_inp = \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "# tar_real = \"A lion in the jungle is sleeping EOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.0902 Accuracy 0.0000\n",
      "Epoch 1 Batch 5 Loss 4.9361 Accuracy 0.0000\n",
      "Epoch 1 Batch 10 Loss 4.9486 Accuracy 0.0000\n",
      "Epoch 1 Batch 15 Loss 4.8304 Accuracy 0.0001\n",
      "Epoch 1 Batch 20 Loss 4.8647 Accuracy 0.0003\n",
      "Epoch 1 Batch 25 Loss 4.8467 Accuracy 0.0030\n",
      "Epoch 1 Batch 30 Loss 4.8648 Accuracy 0.0061\n",
      "Epoch 1 Batch 35 Loss 4.8395 Accuracy 0.0092\n",
      "Epoch 1 Batch 40 Loss 4.7824 Accuracy 0.0118\n",
      "Epoch 1 Batch 45 Loss 4.7560 Accuracy 0.0137\n",
      "Epoch 1 Batch 50 Loss 4.7398 Accuracy 0.0151\n",
      "Epoch 1 Batch 55 Loss 4.7098 Accuracy 0.0164\n",
      "Epoch 1 Batch 60 Loss 4.7053 Accuracy 0.0175\n",
      "Epoch 1 Batch 65 Loss 4.6849 Accuracy 0.0183\n",
      "Epoch 1 Batch 70 Loss 4.7195 Accuracy 0.0192\n",
      "Epoch 1 Batch 75 Loss 4.6983 Accuracy 0.0200\n",
      "Epoch 1 Batch 80 Loss 4.6888 Accuracy 0.0206\n",
      "Epoch 1 Batch 85 Loss 4.7006 Accuracy 0.0212\n",
      "Epoch 1 Batch 90 Loss 4.7087 Accuracy 0.0217\n",
      "Epoch 1 Batch 95 Loss 4.6914 Accuracy 0.0221\n",
      "Epoch 1 Batch 100 Loss 4.6932 Accuracy 0.0225\n",
      "Epoch 1 Batch 105 Loss 4.6966 Accuracy 0.0227\n",
      "Epoch 1 Batch 110 Loss 4.6979 Accuracy 0.0231\n",
      "Epoch 1 Batch 115 Loss 4.6910 Accuracy 0.0234\n",
      "Epoch 1 Batch 120 Loss 4.6990 Accuracy 0.0237\n",
      "Epoch 1 Batch 125 Loss 4.6903 Accuracy 0.0240\n",
      "Epoch 1 Batch 130 Loss 4.6867 Accuracy 0.0242\n",
      "Epoch 1 Batch 135 Loss 4.6796 Accuracy 0.0245\n",
      "Epoch 1 Batch 140 Loss 4.6773 Accuracy 0.0247\n",
      "Epoch 1 Batch 145 Loss 4.6588 Accuracy 0.0248\n",
      "Epoch 1 Batch 150 Loss 4.6594 Accuracy 0.0250\n",
      "Epoch 1 Batch 155 Loss 4.6422 Accuracy 0.0251\n",
      "Epoch 1 Batch 160 Loss 4.6500 Accuracy 0.0253\n",
      "Epoch 1 Batch 165 Loss 4.6358 Accuracy 0.0254\n",
      "Epoch 1 Batch 170 Loss 4.6249 Accuracy 0.0255\n",
      "Epoch 1 Batch 175 Loss 4.6166 Accuracy 0.0257\n",
      "Epoch 1 Batch 180 Loss 4.5983 Accuracy 0.0258\n",
      "Epoch 1 Batch 185 Loss 4.5978 Accuracy 0.0259\n",
      "Epoch 1 Batch 190 Loss 4.5952 Accuracy 0.0261\n",
      "Epoch 1 Batch 195 Loss 4.5903 Accuracy 0.0262\n",
      "Epoch 1 Batch 200 Loss 4.5822 Accuracy 0.0263\n",
      "Epoch 1 Batch 205 Loss 4.5673 Accuracy 0.0264\n",
      "Epoch 1 Batch 210 Loss 4.5585 Accuracy 0.0265\n",
      "Epoch 1 Batch 215 Loss 4.5605 Accuracy 0.0266\n",
      "Epoch 1 Batch 220 Loss 4.5521 Accuracy 0.0267\n",
      "Epoch 1 Batch 225 Loss 4.5436 Accuracy 0.0268\n",
      "Epoch 1 Batch 230 Loss 4.5250 Accuracy 0.0268\n",
      "Epoch 1 Batch 235 Loss 4.5195 Accuracy 0.0269\n",
      "Epoch 1 Batch 240 Loss 4.5087 Accuracy 0.0270\n",
      "Epoch 1 Batch 245 Loss 4.4928 Accuracy 0.0270\n",
      "Epoch 1 Batch 250 Loss 4.4835 Accuracy 0.0271\n",
      "Epoch 1 Batch 255 Loss 4.4641 Accuracy 0.0271\n",
      "Epoch 1 Batch 260 Loss 4.4586 Accuracy 0.0271\n",
      "Epoch 1 Batch 265 Loss 4.4466 Accuracy 0.0272\n",
      "Epoch 1 Batch 270 Loss 4.4317 Accuracy 0.0272\n",
      "Epoch 1 Batch 275 Loss 4.4261 Accuracy 0.0273\n",
      "Epoch 1 Batch 280 Loss 4.4143 Accuracy 0.0274\n",
      "Epoch 1 Batch 285 Loss 4.4023 Accuracy 0.0274\n",
      "Epoch 1 Batch 290 Loss 4.3936 Accuracy 0.0275\n",
      "Epoch 1 Batch 295 Loss 4.3861 Accuracy 0.0276\n",
      "Epoch 1 Batch 300 Loss 4.3806 Accuracy 0.0278\n",
      "Epoch 1 Batch 305 Loss 4.3737 Accuracy 0.0280\n",
      "Epoch 1 Batch 310 Loss 4.3588 Accuracy 0.0282\n",
      "Epoch 1 Batch 315 Loss 4.3478 Accuracy 0.0285\n",
      "Epoch 1 Batch 320 Loss 4.3386 Accuracy 0.0289\n",
      "Epoch 1 Batch 325 Loss 4.3283 Accuracy 0.0292\n",
      "Epoch 1 Batch 330 Loss 4.3137 Accuracy 0.0295\n",
      "Epoch 1 Batch 335 Loss 4.2997 Accuracy 0.0298\n",
      "Epoch 1 Batch 340 Loss 4.2920 Accuracy 0.0301\n",
      "Epoch 1 Batch 345 Loss 4.2840 Accuracy 0.0305\n",
      "Epoch 1 Batch 350 Loss 4.2728 Accuracy 0.0308\n",
      "Epoch 1 Batch 355 Loss 4.2588 Accuracy 0.0312\n",
      "Epoch 1 Batch 360 Loss 4.2475 Accuracy 0.0315\n",
      "Epoch 1 Batch 365 Loss 4.2414 Accuracy 0.0319\n",
      "Epoch 1 Batch 370 Loss 4.2272 Accuracy 0.0322\n",
      "Epoch 1 Batch 375 Loss 4.2176 Accuracy 0.0325\n",
      "Epoch 1 Batch 380 Loss 4.2094 Accuracy 0.0329\n",
      "Epoch 1 Batch 385 Loss 4.1977 Accuracy 0.0332\n",
      "Epoch 1 Batch 390 Loss 4.1866 Accuracy 0.0334\n",
      "Epoch 1 Batch 395 Loss 4.1775 Accuracy 0.0337\n",
      "Epoch 1 Batch 400 Loss 4.1688 Accuracy 0.0340\n",
      "Epoch 1 Batch 405 Loss 4.1597 Accuracy 0.0342\n",
      "Epoch 1 Batch 410 Loss 4.1493 Accuracy 0.0345\n",
      "Epoch 1 Batch 415 Loss 4.1431 Accuracy 0.0348\n",
      "Epoch 1 Batch 420 Loss 4.1383 Accuracy 0.0351\n",
      "Epoch 1 Batch 425 Loss 4.1293 Accuracy 0.0353\n",
      "Epoch 1 Batch 430 Loss 4.1237 Accuracy 0.0356\n",
      "Epoch 1 Batch 435 Loss 4.1162 Accuracy 0.0359\n",
      "Epoch 1 Batch 440 Loss 4.1065 Accuracy 0.0362\n",
      "Epoch 1 Batch 445 Loss 4.0993 Accuracy 0.0366\n",
      "Epoch 1 Batch 450 Loss 4.0937 Accuracy 0.0369\n",
      "Epoch 1 Batch 455 Loss 4.0852 Accuracy 0.0372\n",
      "Epoch 1 Batch 460 Loss 4.0800 Accuracy 0.0375\n",
      "Epoch 1 Batch 465 Loss 4.0725 Accuracy 0.0379\n",
      "Epoch 1 Batch 470 Loss 4.0658 Accuracy 0.0382\n",
      "Epoch 1 Batch 475 Loss 4.0564 Accuracy 0.0385\n",
      "Epoch 1 Batch 480 Loss 4.0513 Accuracy 0.0389\n",
      "Epoch 1 Batch 485 Loss 4.0453 Accuracy 0.0392\n",
      "Epoch 1 Batch 490 Loss 4.0386 Accuracy 0.0395\n",
      "Epoch 1 Batch 495 Loss 4.0303 Accuracy 0.0397\n",
      "Epoch 1 Batch 500 Loss 4.0202 Accuracy 0.0400\n",
      "Epoch 1 Batch 505 Loss 4.0120 Accuracy 0.0403\n",
      "Epoch 1 Batch 510 Loss 4.0039 Accuracy 0.0405\n",
      "Epoch 1 Batch 515 Loss 3.9962 Accuracy 0.0408\n",
      "Epoch 1 Batch 520 Loss 3.9867 Accuracy 0.0410\n",
      "Epoch 1 Batch 525 Loss 3.9796 Accuracy 0.0413\n",
      "Epoch 1 Batch 530 Loss 3.9720 Accuracy 0.0415\n",
      "Epoch 1 Batch 535 Loss 3.9643 Accuracy 0.0418\n",
      "Epoch 1 Batch 540 Loss 3.9573 Accuracy 0.0421\n",
      "Epoch 1 Batch 545 Loss 3.9496 Accuracy 0.0423\n",
      "Epoch 1 Batch 550 Loss 3.9443 Accuracy 0.0425\n",
      "Epoch 1 Batch 555 Loss 3.9368 Accuracy 0.0428\n",
      "Epoch 1 Batch 560 Loss 3.9328 Accuracy 0.0431\n",
      "Epoch 1 Batch 565 Loss 3.9279 Accuracy 0.0433\n",
      "Epoch 1 Batch 570 Loss 3.9238 Accuracy 0.0435\n",
      "Epoch 1 Batch 575 Loss 3.9175 Accuracy 0.0437\n",
      "Epoch 1 Batch 580 Loss 3.9124 Accuracy 0.0440\n",
      "Epoch 1 Batch 585 Loss 3.9086 Accuracy 0.0443\n",
      "Epoch 1 Batch 590 Loss 3.9015 Accuracy 0.0446\n",
      "Epoch 1 Batch 595 Loss 3.8935 Accuracy 0.0447\n",
      "Epoch 1 Batch 600 Loss 3.8870 Accuracy 0.0450\n",
      "Epoch 1 Batch 605 Loss 3.8824 Accuracy 0.0452\n",
      "Epoch 1 Batch 610 Loss 3.8766 Accuracy 0.0454\n",
      "Epoch 1 Batch 615 Loss 3.8721 Accuracy 0.0457\n",
      "Epoch 1 Batch 620 Loss 3.8669 Accuracy 0.0460\n",
      "Epoch 1 Batch 625 Loss 3.8630 Accuracy 0.0463\n",
      "Epoch 1 Batch 630 Loss 3.8575 Accuracy 0.0466\n",
      "Epoch 1 Batch 635 Loss 3.8509 Accuracy 0.0469\n",
      "Epoch 1 Batch 640 Loss 3.8479 Accuracy 0.0471\n",
      "Epoch 1 Batch 645 Loss 3.8418 Accuracy 0.0474\n",
      "Epoch 1 Batch 650 Loss 3.8370 Accuracy 0.0476\n",
      "Epoch 1 Batch 655 Loss 3.8305 Accuracy 0.0479\n",
      "Epoch 1 Batch 660 Loss 3.8254 Accuracy 0.0482\n",
      "Epoch 1 Batch 665 Loss 3.8208 Accuracy 0.0485\n",
      "Epoch 1 Batch 670 Loss 3.8147 Accuracy 0.0488\n",
      "Epoch 1 Batch 675 Loss 3.8077 Accuracy 0.0491\n",
      "Epoch 1 Batch 680 Loss 3.8029 Accuracy 0.0493\n",
      "Epoch 1 Batch 685 Loss 3.7976 Accuracy 0.0496\n",
      "Epoch 1 Batch 690 Loss 3.7916 Accuracy 0.0499\n",
      "Epoch 1 Batch 695 Loss 3.7839 Accuracy 0.0502\n",
      "Epoch 1 Batch 700 Loss 3.7772 Accuracy 0.0504\n",
      "Epoch 1 Batch 705 Loss 3.7726 Accuracy 0.0506\n",
      "Epoch 1 Batch 710 Loss 3.7683 Accuracy 0.0509\n",
      "Epoch 1 Batch 715 Loss 3.7627 Accuracy 0.0511\n",
      "Epoch 1 Batch 720 Loss 3.7587 Accuracy 0.0514\n",
      "Epoch 1 Batch 725 Loss 3.7530 Accuracy 0.0517\n",
      "Epoch 1 Batch 730 Loss 3.7492 Accuracy 0.0520\n",
      "Epoch 1 Batch 735 Loss 3.7449 Accuracy 0.0523\n",
      "Epoch 1 Batch 740 Loss 3.7414 Accuracy 0.0526\n",
      "Epoch 1 Batch 745 Loss 3.7357 Accuracy 0.0529\n",
      "Epoch 1 Batch 750 Loss 3.7323 Accuracy 0.0532\n",
      "Epoch 1 Batch 755 Loss 3.7293 Accuracy 0.0535\n",
      "Epoch 1 Batch 760 Loss 3.7252 Accuracy 0.0537\n",
      "Epoch 1 Batch 765 Loss 3.7212 Accuracy 0.0540\n",
      "Epoch 1 Batch 770 Loss 3.7178 Accuracy 0.0543\n",
      "Epoch 1 Batch 775 Loss 3.7128 Accuracy 0.0545\n",
      "Epoch 1 Batch 780 Loss 3.7089 Accuracy 0.0548\n",
      "Epoch 1 Batch 785 Loss 3.7052 Accuracy 0.0551\n",
      "Epoch 1 Batch 790 Loss 3.7015 Accuracy 0.0555\n",
      "Epoch 1 Batch 795 Loss 3.6957 Accuracy 0.0557\n",
      "Epoch 1 Batch 800 Loss 3.6917 Accuracy 0.0561\n",
      "Epoch 1 Batch 805 Loss 3.6869 Accuracy 0.0563\n",
      "Epoch 1 Batch 810 Loss 3.6850 Accuracy 0.0567\n",
      "Epoch 1 Batch 815 Loss 3.6808 Accuracy 0.0569\n",
      "Epoch 1 Batch 820 Loss 3.6753 Accuracy 0.0572\n",
      "Epoch 1 Batch 825 Loss 3.6707 Accuracy 0.0575\n",
      "Epoch 1 Batch 830 Loss 3.6664 Accuracy 0.0578\n",
      "Epoch 1 Batch 835 Loss 3.6625 Accuracy 0.0581\n",
      "Epoch 1 Batch 840 Loss 3.6578 Accuracy 0.0583\n",
      "Epoch 1 Batch 845 Loss 3.6525 Accuracy 0.0585\n",
      "Epoch 1 Batch 850 Loss 3.6485 Accuracy 0.0588\n",
      "Epoch 1 Batch 855 Loss 3.6438 Accuracy 0.0590\n",
      "Epoch 1 Batch 860 Loss 3.6409 Accuracy 0.0593\n",
      "Epoch 1 Batch 865 Loss 3.6368 Accuracy 0.0596\n",
      "Epoch 1 Batch 870 Loss 3.6337 Accuracy 0.0599\n",
      "Epoch 1 Batch 875 Loss 3.6305 Accuracy 0.0601\n",
      "Epoch 1 Batch 880 Loss 3.6263 Accuracy 0.0604\n",
      "Epoch 1 Batch 885 Loss 3.6226 Accuracy 0.0607\n",
      "Epoch 1 Batch 890 Loss 3.6179 Accuracy 0.0610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 895 Loss 3.6132 Accuracy 0.0613\n",
      "Epoch 1 Batch 900 Loss 3.6088 Accuracy 0.0615\n",
      "Epoch 1 Batch 905 Loss 3.6054 Accuracy 0.0618\n",
      "Epoch 1 Batch 910 Loss 3.6018 Accuracy 0.0620\n",
      "Epoch 1 Batch 915 Loss 3.5990 Accuracy 0.0623\n",
      "Epoch 1 Batch 920 Loss 3.5946 Accuracy 0.0626\n",
      "Epoch 1 Batch 925 Loss 3.5896 Accuracy 0.0628\n",
      "Epoch 1 Batch 930 Loss 3.5871 Accuracy 0.0631\n",
      "Epoch 1 Batch 935 Loss 3.5827 Accuracy 0.0633\n",
      "Epoch 1 Batch 940 Loss 3.5802 Accuracy 0.0636\n",
      "Epoch 1 Batch 945 Loss 3.5780 Accuracy 0.0639\n",
      "Epoch 1 Batch 950 Loss 3.5750 Accuracy 0.0642\n",
      "Epoch 1 Batch 955 Loss 3.5706 Accuracy 0.0644\n",
      "Epoch 1 Batch 960 Loss 3.5671 Accuracy 0.0647\n",
      "Epoch 1 Batch 965 Loss 3.5644 Accuracy 0.0650\n",
      "Epoch 1 Batch 970 Loss 3.5605 Accuracy 0.0653\n",
      "Epoch 1 Batch 975 Loss 3.5564 Accuracy 0.0655\n",
      "Epoch 1 Batch 980 Loss 3.5523 Accuracy 0.0658\n",
      "Epoch 1 Batch 985 Loss 3.5482 Accuracy 0.0660\n",
      "Epoch 1 Batch 990 Loss 3.5450 Accuracy 0.0662\n",
      "Epoch 1 Batch 995 Loss 3.5420 Accuracy 0.0665\n",
      "Epoch 1 Batch 1000 Loss 3.5399 Accuracy 0.0667\n",
      "Epoch 1 Batch 1005 Loss 3.5354 Accuracy 0.0669\n",
      "Epoch 1 Batch 1010 Loss 3.5318 Accuracy 0.0672\n",
      "Epoch 1 Batch 1015 Loss 3.5289 Accuracy 0.0674\n",
      "Epoch 1 Batch 1020 Loss 3.5251 Accuracy 0.0676\n",
      "Epoch 1 Batch 1025 Loss 3.5215 Accuracy 0.0678\n",
      "Epoch 1 Batch 1030 Loss 3.5185 Accuracy 0.0680\n",
      "Epoch 1 Batch 1035 Loss 3.5163 Accuracy 0.0683\n",
      "Epoch 1 Batch 1040 Loss 3.5137 Accuracy 0.0685\n",
      "Epoch 1 Batch 1045 Loss 3.5107 Accuracy 0.0688\n",
      "Epoch 1 Batch 1050 Loss 3.5080 Accuracy 0.0690\n",
      "Epoch 1 Batch 1055 Loss 3.5048 Accuracy 0.0693\n",
      "Epoch 1 Batch 1060 Loss 3.5013 Accuracy 0.0695\n",
      "Epoch 1 Batch 1065 Loss 3.4974 Accuracy 0.0697\n",
      "Epoch 1 Batch 1070 Loss 3.4947 Accuracy 0.0700\n",
      "Epoch 1 Batch 1075 Loss 3.4922 Accuracy 0.0702\n",
      "Epoch 1 Batch 1080 Loss 3.4890 Accuracy 0.0704\n",
      "Epoch 1 Batch 1085 Loss 3.4858 Accuracy 0.0706\n",
      "Epoch 1 Batch 1090 Loss 3.4830 Accuracy 0.0708\n",
      "Epoch 1 Batch 1095 Loss 3.4796 Accuracy 0.0711\n",
      "Epoch 1 Batch 1100 Loss 3.4771 Accuracy 0.0713\n",
      "Epoch 1 Batch 1105 Loss 3.4741 Accuracy 0.0715\n",
      "Epoch 1 Batch 1110 Loss 3.4715 Accuracy 0.0718\n",
      "Epoch 1 Batch 1115 Loss 3.4688 Accuracy 0.0720\n",
      "Epoch 1 Batch 1120 Loss 3.4657 Accuracy 0.0721\n",
      "Epoch 1 Batch 1125 Loss 3.4631 Accuracy 0.0724\n",
      "Epoch 1 Batch 1130 Loss 3.4602 Accuracy 0.0726\n",
      "Epoch 1 Batch 1135 Loss 3.4579 Accuracy 0.0728\n",
      "Epoch 1 Batch 1140 Loss 3.4545 Accuracy 0.0730\n",
      "Epoch 1 Batch 1145 Loss 3.4504 Accuracy 0.0732\n",
      "Epoch 1 Batch 1150 Loss 3.4487 Accuracy 0.0734\n",
      "Epoch 1 Batch 1155 Loss 3.4463 Accuracy 0.0736\n",
      "Epoch 1 Batch 1160 Loss 3.4439 Accuracy 0.0738\n",
      "Epoch 1 Batch 1165 Loss 3.4408 Accuracy 0.0740\n",
      "Epoch 1 Batch 1170 Loss 3.4381 Accuracy 0.0742\n",
      "Epoch 1 Batch 1175 Loss 3.4363 Accuracy 0.0744\n",
      "Epoch 1 Batch 1180 Loss 3.4347 Accuracy 0.0746\n",
      "Epoch 1 Batch 1185 Loss 3.4324 Accuracy 0.0748\n",
      "Epoch 1 Batch 1190 Loss 3.4302 Accuracy 0.0750\n",
      "Epoch 1 Batch 1195 Loss 3.4277 Accuracy 0.0752\n",
      "Epoch 1 Batch 1200 Loss 3.4257 Accuracy 0.0754\n",
      "Epoch 1 Batch 1205 Loss 3.4237 Accuracy 0.0756\n",
      "Epoch 1 Batch 1210 Loss 3.4207 Accuracy 0.0758\n",
      "Epoch 1 Batch 1215 Loss 3.4164 Accuracy 0.0760\n",
      "Epoch 1 Batch 1220 Loss 3.4131 Accuracy 0.0762\n",
      "Epoch 1 Batch 1225 Loss 3.4107 Accuracy 0.0764\n",
      "Epoch 1 Batch 1230 Loss 3.4086 Accuracy 0.0766\n",
      "Epoch 1 Batch 1235 Loss 3.4064 Accuracy 0.0768\n",
      "Epoch 1 Batch 1240 Loss 3.4031 Accuracy 0.0769\n",
      "Epoch 1 Batch 1245 Loss 3.4008 Accuracy 0.0772\n",
      "Epoch 1 Batch 1250 Loss 3.3984 Accuracy 0.0774\n",
      "Epoch 1 Batch 1255 Loss 3.3956 Accuracy 0.0775\n",
      "Epoch 1 Batch 1260 Loss 3.3936 Accuracy 0.0777\n",
      "Epoch 1 Batch 1265 Loss 3.3900 Accuracy 0.0779\n",
      "Epoch 1 Batch 1270 Loss 3.3870 Accuracy 0.0781\n",
      "Epoch 1 Batch 1275 Loss 3.3844 Accuracy 0.0783\n",
      "Epoch 1 Batch 1280 Loss 3.3812 Accuracy 0.0784\n",
      "Epoch 1 Batch 1285 Loss 3.3786 Accuracy 0.0786\n",
      "Epoch 1 Batch 1290 Loss 3.3765 Accuracy 0.0787\n",
      "Epoch 1 Batch 1295 Loss 3.3740 Accuracy 0.0789\n",
      "Epoch 1 Batch 1300 Loss 3.3715 Accuracy 0.0791\n",
      "Epoch 1 Batch 1305 Loss 3.3689 Accuracy 0.0793\n",
      "Epoch 1 Batch 1310 Loss 3.3664 Accuracy 0.0794\n",
      "Epoch 1 Batch 1315 Loss 3.3644 Accuracy 0.0797\n",
      "Epoch 1 Batch 1320 Loss 3.3624 Accuracy 0.0799\n",
      "Epoch 1 Batch 1325 Loss 3.3590 Accuracy 0.0800\n",
      "Epoch 1 Batch 1330 Loss 3.3573 Accuracy 0.0802\n",
      "Epoch 1 Batch 1335 Loss 3.3557 Accuracy 0.0804\n",
      "Epoch 1 Batch 1340 Loss 3.3530 Accuracy 0.0806\n",
      "Epoch 1 Batch 1345 Loss 3.3502 Accuracy 0.0807\n",
      "Epoch 1 Batch 1350 Loss 3.3476 Accuracy 0.0809\n",
      "Epoch 1 Batch 1355 Loss 3.3449 Accuracy 0.0811\n",
      "Epoch 1 Batch 1360 Loss 3.3427 Accuracy 0.0813\n",
      "Epoch 1 Batch 1365 Loss 3.3407 Accuracy 0.0814\n",
      "Epoch 1 Batch 1370 Loss 3.3383 Accuracy 0.0816\n",
      "Epoch 1 Batch 1375 Loss 3.3356 Accuracy 0.0817\n",
      "Epoch 1 Batch 1380 Loss 3.3334 Accuracy 0.0819\n",
      "Epoch 1 Batch 1385 Loss 3.3300 Accuracy 0.0821\n",
      "Epoch 1 Batch 1390 Loss 3.3272 Accuracy 0.0822\n",
      "Epoch 1 Batch 1395 Loss 3.3252 Accuracy 0.0824\n",
      "Epoch 1 Batch 1400 Loss 3.3231 Accuracy 0.0826\n",
      "Epoch 1 Batch 1405 Loss 3.3210 Accuracy 0.0828\n",
      "Epoch 1 Batch 1410 Loss 3.3193 Accuracy 0.0829\n",
      "Epoch 1 Batch 1415 Loss 3.3177 Accuracy 0.0831\n",
      "Epoch 1 Batch 1420 Loss 3.3159 Accuracy 0.0832\n",
      "Epoch 1 Batch 1425 Loss 3.3127 Accuracy 0.0834\n",
      "Epoch 1 Batch 1430 Loss 3.3108 Accuracy 0.0835\n",
      "Epoch 1 Batch 1435 Loss 3.3090 Accuracy 0.0837\n",
      "Epoch 1 Batch 1440 Loss 3.3067 Accuracy 0.0839\n",
      "Epoch 1 Batch 1445 Loss 3.3044 Accuracy 0.0841\n",
      "Epoch 1 Batch 1450 Loss 3.3026 Accuracy 0.0842\n",
      "Epoch 1 Batch 1455 Loss 3.3007 Accuracy 0.0844\n",
      "Epoch 1 Batch 1460 Loss 3.2977 Accuracy 0.0845\n",
      "Epoch 1 Batch 1465 Loss 3.2964 Accuracy 0.0847\n",
      "Epoch 1 Batch 1470 Loss 3.2953 Accuracy 0.0848\n",
      "Epoch 1 Batch 1475 Loss 3.2938 Accuracy 0.0850\n",
      "Epoch 1 Batch 1480 Loss 3.2922 Accuracy 0.0852\n",
      "Epoch 1 Batch 1485 Loss 3.2903 Accuracy 0.0853\n",
      "Epoch 1 Batch 1490 Loss 3.2888 Accuracy 0.0855\n",
      "Epoch 1 Batch 1495 Loss 3.2873 Accuracy 0.0857\n",
      "Epoch 1 Batch 1500 Loss 3.2858 Accuracy 0.0859\n",
      "Epoch 1 Batch 1505 Loss 3.2839 Accuracy 0.0860\n",
      "Epoch 1 Batch 1510 Loss 3.2818 Accuracy 0.0862\n",
      "Epoch 1 Batch 1515 Loss 3.2801 Accuracy 0.0863\n",
      "Epoch 1 Batch 1520 Loss 3.2791 Accuracy 0.0864\n",
      "Epoch 1 Batch 1525 Loss 3.2773 Accuracy 0.0866\n",
      "Epoch 1 Batch 1530 Loss 3.2747 Accuracy 0.0867\n",
      "Epoch 1 Batch 1535 Loss 3.2720 Accuracy 0.0869\n",
      "Epoch 1 Batch 1540 Loss 3.2697 Accuracy 0.0870\n",
      "Epoch 1 Batch 1545 Loss 3.2678 Accuracy 0.0872\n",
      "Epoch 1 Batch 1550 Loss 3.2659 Accuracy 0.0874\n",
      "Epoch 1 Batch 1555 Loss 3.2638 Accuracy 0.0875\n",
      "Epoch 1 Batch 1560 Loss 3.2625 Accuracy 0.0877\n",
      "Epoch 1 Batch 1565 Loss 3.2615 Accuracy 0.0878\n",
      "Epoch 1 Batch 1570 Loss 3.2602 Accuracy 0.0880\n",
      "Epoch 1 Batch 1575 Loss 3.2588 Accuracy 0.0881\n",
      "Epoch 1 Batch 1580 Loss 3.2571 Accuracy 0.0883\n",
      "Epoch 1 Batch 1585 Loss 3.2554 Accuracy 0.0884\n",
      "Epoch 1 Batch 1590 Loss 3.2533 Accuracy 0.0886\n",
      "Epoch 1 Batch 1595 Loss 3.2513 Accuracy 0.0887\n",
      "Epoch 1 Batch 1600 Loss 3.2489 Accuracy 0.0889\n",
      "Epoch 1 Batch 1605 Loss 3.2463 Accuracy 0.0890\n",
      "Epoch 1 Batch 1610 Loss 3.2448 Accuracy 0.0891\n",
      "Epoch 1 Batch 1615 Loss 3.2439 Accuracy 0.0893\n",
      "Epoch 1 Batch 1620 Loss 3.2409 Accuracy 0.0894\n",
      "Epoch 1 Batch 1625 Loss 3.2388 Accuracy 0.0896\n",
      "Epoch 1 Batch 1630 Loss 3.2369 Accuracy 0.0897\n",
      "Epoch 1 Batch 1635 Loss 3.2352 Accuracy 0.0898\n",
      "Epoch 1 Batch 1640 Loss 3.2336 Accuracy 0.0899\n",
      "Epoch 1 Batch 1645 Loss 3.2315 Accuracy 0.0900\n",
      "Epoch 1 Batch 1650 Loss 3.2294 Accuracy 0.0902\n",
      "Epoch 1 Batch 1655 Loss 3.2283 Accuracy 0.0903\n",
      "Epoch 1 Batch 1660 Loss 3.2265 Accuracy 0.0904\n",
      "Epoch 1 Batch 1665 Loss 3.2244 Accuracy 0.0906\n",
      "Epoch 1 Batch 1670 Loss 3.2225 Accuracy 0.0907\n",
      "Epoch 1 Batch 1675 Loss 3.2214 Accuracy 0.0909\n",
      "Epoch 1 Batch 1680 Loss 3.2190 Accuracy 0.0910\n",
      "Epoch 1 Batch 1685 Loss 3.2174 Accuracy 0.0912\n",
      "Epoch 1 Batch 1690 Loss 3.2167 Accuracy 0.0913\n",
      "Epoch 1 Batch 1695 Loss 3.2142 Accuracy 0.0915\n",
      "Epoch 1 Batch 1700 Loss 3.2131 Accuracy 0.0916\n",
      "Epoch 1 Batch 1705 Loss 3.2099 Accuracy 0.0918\n",
      "Epoch 1 Batch 1710 Loss 3.2084 Accuracy 0.0919\n",
      "Epoch 1 Batch 1715 Loss 3.2062 Accuracy 0.0921\n",
      "Epoch 1 Batch 1720 Loss 3.2041 Accuracy 0.0922\n",
      "Epoch 1 Batch 1725 Loss 3.2023 Accuracy 0.0923\n",
      "Epoch 1 Batch 1730 Loss 3.2009 Accuracy 0.0924\n",
      "Epoch 1 Batch 1735 Loss 3.2000 Accuracy 0.0926\n",
      "Epoch 1 Batch 1740 Loss 3.1983 Accuracy 0.0927\n",
      "Epoch 1 Batch 1745 Loss 3.1973 Accuracy 0.0928\n",
      "Epoch 1 Batch 1750 Loss 3.1954 Accuracy 0.0929\n",
      "Epoch 1 Batch 1755 Loss 3.1939 Accuracy 0.0930\n",
      "Epoch 1 Batch 1760 Loss 3.1925 Accuracy 0.0932\n",
      "Epoch 1 Batch 1765 Loss 3.1913 Accuracy 0.0933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 1770 Loss 3.1896 Accuracy 0.0934\n",
      "Epoch 1 Batch 1775 Loss 3.1871 Accuracy 0.0935\n",
      "Epoch 1 Batch 1780 Loss 3.1851 Accuracy 0.0937\n",
      "Epoch 1 Batch 1785 Loss 3.1832 Accuracy 0.0938\n",
      "Epoch 1 Batch 1790 Loss 3.1813 Accuracy 0.0939\n",
      "Epoch 1 Batch 1795 Loss 3.1798 Accuracy 0.0941\n",
      "Epoch 1 Batch 1800 Loss 3.1788 Accuracy 0.0943\n",
      "Epoch 1 Batch 1805 Loss 3.1775 Accuracy 0.0944\n",
      "Epoch 1 Batch 1810 Loss 3.1763 Accuracy 0.0945\n",
      "Epoch 1 Batch 1815 Loss 3.1755 Accuracy 0.0946\n",
      "Epoch 1 Batch 1820 Loss 3.1741 Accuracy 0.0948\n",
      "Epoch 1 Batch 1825 Loss 3.1730 Accuracy 0.0949\n",
      "Epoch 1 Batch 1830 Loss 3.1712 Accuracy 0.0950\n",
      "Epoch 1 Batch 1835 Loss 3.1689 Accuracy 0.0951\n",
      "Epoch 1 Batch 1840 Loss 3.1676 Accuracy 0.0953\n",
      "Epoch 1 Batch 1845 Loss 3.1662 Accuracy 0.0954\n",
      "Epoch 1 Batch 1850 Loss 3.1643 Accuracy 0.0955\n",
      "Epoch 1 Batch 1855 Loss 3.1629 Accuracy 0.0956\n",
      "Epoch 1 Batch 1860 Loss 3.1612 Accuracy 0.0957\n",
      "Epoch 1 Batch 1865 Loss 3.1598 Accuracy 0.0959\n",
      "Epoch 1 Batch 1870 Loss 3.1579 Accuracy 0.0960\n",
      "Epoch 1 Batch 1875 Loss 3.1563 Accuracy 0.0961\n",
      "Epoch 1 Batch 1880 Loss 3.1546 Accuracy 0.0962\n",
      "Epoch 1 Batch 1885 Loss 3.1529 Accuracy 0.0963\n",
      "Epoch 1 Batch 1890 Loss 3.1517 Accuracy 0.0964\n",
      "Epoch 1 Batch 1895 Loss 3.1496 Accuracy 0.0965\n",
      "Epoch 1 Batch 1900 Loss 3.1478 Accuracy 0.0966\n",
      "Epoch 1 Batch 1905 Loss 3.1458 Accuracy 0.0967\n",
      "Epoch 1 Batch 1910 Loss 3.1446 Accuracy 0.0968\n",
      "Epoch 1 Batch 1915 Loss 3.1433 Accuracy 0.0969\n",
      "Epoch 1 Batch 1920 Loss 3.1428 Accuracy 0.0970\n",
      "Epoch 1 Batch 1925 Loss 3.1417 Accuracy 0.0971\n",
      "Epoch 1 Batch 1930 Loss 3.1405 Accuracy 0.0973\n",
      "Epoch 1 Batch 1935 Loss 3.1394 Accuracy 0.0974\n",
      "Epoch 1 Batch 1940 Loss 3.1377 Accuracy 0.0975\n",
      "Epoch 1 Batch 1945 Loss 3.1357 Accuracy 0.0976\n",
      "Epoch 1 Batch 1950 Loss 3.1344 Accuracy 0.0977\n",
      "Epoch 1 Batch 1955 Loss 3.1325 Accuracy 0.0978\n",
      "Epoch 1 Batch 1960 Loss 3.1307 Accuracy 0.0979\n",
      "Epoch 1 Batch 1965 Loss 3.1296 Accuracy 0.0980\n",
      "Epoch 1 Batch 1970 Loss 3.1286 Accuracy 0.0981\n",
      "Epoch 1 Batch 1975 Loss 3.1267 Accuracy 0.0982\n",
      "Epoch 1 Batch 1980 Loss 3.1252 Accuracy 0.0984\n",
      "Epoch 1 Batch 1985 Loss 3.1243 Accuracy 0.0985\n",
      "Epoch 1 Batch 1990 Loss 3.1227 Accuracy 0.0986\n",
      "Epoch 1 Batch 1995 Loss 3.1211 Accuracy 0.0987\n",
      "Epoch 1 Batch 2000 Loss 3.1197 Accuracy 0.0988\n",
      "Epoch 1 Batch 2005 Loss 3.1187 Accuracy 0.0989\n",
      "Epoch 1 Batch 2010 Loss 3.1173 Accuracy 0.0990\n",
      "Epoch 1 Batch 2015 Loss 3.1160 Accuracy 0.0991\n",
      "Epoch 1 Batch 2020 Loss 3.1142 Accuracy 0.0992\n",
      "Epoch 1 Batch 2025 Loss 3.1129 Accuracy 0.0993\n",
      "Epoch 1 Batch 2030 Loss 3.1121 Accuracy 0.0994\n",
      "Epoch 1 Batch 2035 Loss 3.1110 Accuracy 0.0995\n",
      "Epoch 1 Batch 2040 Loss 3.1097 Accuracy 0.0996\n",
      "Epoch 1 Batch 2045 Loss 3.1084 Accuracy 0.0997\n",
      "Epoch 1 Batch 2050 Loss 3.1076 Accuracy 0.0998\n",
      "Epoch 1 Batch 2055 Loss 3.1066 Accuracy 0.0999\n",
      "Epoch 1 Batch 2060 Loss 3.1055 Accuracy 0.1001\n",
      "Epoch 1 Batch 2065 Loss 3.1049 Accuracy 0.1002\n",
      "Epoch 1 Batch 2070 Loss 3.1036 Accuracy 0.1003\n",
      "Epoch 1 Batch 2075 Loss 3.1022 Accuracy 0.1004\n",
      "Epoch 1 Batch 2080 Loss 3.1004 Accuracy 0.1005\n",
      "Epoch 1 Batch 2085 Loss 3.0991 Accuracy 0.1006\n",
      "Epoch 1 Batch 2090 Loss 3.0981 Accuracy 0.1007\n",
      "Epoch 1 Batch 2095 Loss 3.0965 Accuracy 0.1007\n",
      "Epoch 1 Batch 2100 Loss 3.0951 Accuracy 0.1008\n",
      "Epoch 1 Batch 2105 Loss 3.0939 Accuracy 0.1010\n",
      "Epoch 1 Batch 2110 Loss 3.0926 Accuracy 0.1011\n",
      "Epoch 1 Batch 2115 Loss 3.0914 Accuracy 0.1012\n",
      "Epoch 1 Batch 2120 Loss 3.0907 Accuracy 0.1013\n",
      "Epoch 1 Batch 2125 Loss 3.0889 Accuracy 0.1014\n",
      "Epoch 1 Batch 2130 Loss 3.0878 Accuracy 0.1014\n",
      "Epoch 1 Batch 2135 Loss 3.0865 Accuracy 0.1016\n",
      "Epoch 1 Batch 2140 Loss 3.0855 Accuracy 0.1017\n",
      "Epoch 1 Batch 2145 Loss 3.0841 Accuracy 0.1018\n",
      "Epoch 1 Batch 2150 Loss 3.0830 Accuracy 0.1019\n",
      "Epoch 1 Batch 2155 Loss 3.0820 Accuracy 0.1020\n",
      "Epoch 1 Batch 2160 Loss 3.0809 Accuracy 0.1021\n",
      "Epoch 1 Batch 2165 Loss 3.0799 Accuracy 0.1022\n",
      "Epoch 1 Batch 2170 Loss 3.0791 Accuracy 0.1023\n",
      "Epoch 1 Batch 2175 Loss 3.0785 Accuracy 0.1024\n",
      "Epoch 1 Batch 2180 Loss 3.0776 Accuracy 0.1025\n",
      "Epoch 1 Batch 2185 Loss 3.0768 Accuracy 0.1026\n",
      "Epoch 1 Batch 2190 Loss 3.0752 Accuracy 0.1027\n",
      "Epoch 1 Batch 2195 Loss 3.0739 Accuracy 0.1027\n",
      "Epoch 1 Batch 2200 Loss 3.0726 Accuracy 0.1028\n",
      "Epoch 1 Batch 2205 Loss 3.0713 Accuracy 0.1029\n",
      "Epoch 1 Batch 2210 Loss 3.0707 Accuracy 0.1030\n",
      "Epoch 1 Batch 2215 Loss 3.0700 Accuracy 0.1031\n",
      "Epoch 1 Batch 2220 Loss 3.0688 Accuracy 0.1032\n",
      "Epoch 1 Batch 2225 Loss 3.0676 Accuracy 0.1033\n",
      "Epoch 1 Batch 2230 Loss 3.0664 Accuracy 0.1034\n",
      "Epoch 1 Batch 2235 Loss 3.0652 Accuracy 0.1034\n",
      "Epoch 1 Batch 2240 Loss 3.0642 Accuracy 0.1035\n",
      "Epoch 1 Batch 2245 Loss 3.0634 Accuracy 0.1036\n",
      "Epoch 1 Batch 2250 Loss 3.0627 Accuracy 0.1037\n",
      "Epoch 1 Batch 2255 Loss 3.0622 Accuracy 0.1038\n",
      "Epoch 1 Batch 2260 Loss 3.0613 Accuracy 0.1039\n",
      "Epoch 1 Batch 2265 Loss 3.0603 Accuracy 0.1040\n",
      "Epoch 1 Batch 2270 Loss 3.0587 Accuracy 0.1041\n",
      "Epoch 1 Batch 2275 Loss 3.0572 Accuracy 0.1042\n",
      "Epoch 1 Batch 2280 Loss 3.0560 Accuracy 0.1043\n",
      "Epoch 1 Batch 2285 Loss 3.0555 Accuracy 0.1044\n",
      "Epoch 1 Batch 2290 Loss 3.0548 Accuracy 0.1045\n",
      "Epoch 1 Batch 2295 Loss 3.0536 Accuracy 0.1045\n",
      "Epoch 1 Batch 2300 Loss 3.0526 Accuracy 0.1046\n",
      "Epoch 1 Batch 2305 Loss 3.0518 Accuracy 0.1047\n",
      "Epoch 1 Batch 2310 Loss 3.0514 Accuracy 0.1048\n",
      "Epoch 1 Batch 2315 Loss 3.0503 Accuracy 0.1049\n",
      "Epoch 1 Batch 2320 Loss 3.0489 Accuracy 0.1050\n",
      "Epoch 1 Batch 2325 Loss 3.0479 Accuracy 0.1050\n",
      "Epoch 1 Batch 2330 Loss 3.0469 Accuracy 0.1051\n",
      "Epoch 1 Batch 2335 Loss 3.0460 Accuracy 0.1052\n",
      "Epoch 1 Batch 2340 Loss 3.0452 Accuracy 0.1053\n",
      "Epoch 1 Batch 2345 Loss 3.0436 Accuracy 0.1054\n",
      "Epoch 1 Batch 2350 Loss 3.0423 Accuracy 0.1055\n",
      "Epoch 1 Batch 2355 Loss 3.0413 Accuracy 0.1056\n",
      "Epoch 1 Batch 2360 Loss 3.0400 Accuracy 0.1056\n",
      "Epoch 1 Batch 2365 Loss 3.0390 Accuracy 0.1057\n",
      "Epoch 1 Batch 2370 Loss 3.0382 Accuracy 0.1058\n",
      "Epoch 1 Batch 2375 Loss 3.0376 Accuracy 0.1059\n",
      "Epoch 1 Batch 2380 Loss 3.0364 Accuracy 0.1060\n",
      "Epoch 1 Batch 2385 Loss 3.0355 Accuracy 0.1061\n",
      "Epoch 1 Batch 2390 Loss 3.0346 Accuracy 0.1062\n",
      "Epoch 1 Batch 2395 Loss 3.0330 Accuracy 0.1062\n",
      "Epoch 1 Batch 2400 Loss 3.0322 Accuracy 0.1063\n",
      "Epoch 1 Batch 2405 Loss 3.0309 Accuracy 0.1064\n",
      "Epoch 1 Batch 2410 Loss 3.0298 Accuracy 0.1065\n",
      "Epoch 1 Batch 2415 Loss 3.0289 Accuracy 0.1066\n",
      "Epoch 1 Batch 2420 Loss 3.0278 Accuracy 0.1066\n",
      "Epoch 1 Batch 2425 Loss 3.0268 Accuracy 0.1067\n",
      "Epoch 1 Batch 2430 Loss 3.0257 Accuracy 0.1068\n",
      "Epoch 1 Batch 2435 Loss 3.0247 Accuracy 0.1069\n",
      "Epoch 1 Batch 2440 Loss 3.0243 Accuracy 0.1070\n",
      "Epoch 1 Batch 2445 Loss 3.0236 Accuracy 0.1070\n",
      "Epoch 1 Batch 2450 Loss 3.0226 Accuracy 0.1071\n",
      "Epoch 1 Batch 2455 Loss 3.0220 Accuracy 0.1072\n",
      "Epoch 1 Batch 2460 Loss 3.0213 Accuracy 0.1072\n",
      "Epoch 1 Batch 2465 Loss 3.0200 Accuracy 0.1073\n",
      "Epoch 1 Batch 2470 Loss 3.0190 Accuracy 0.1074\n",
      "Epoch 1 Batch 2475 Loss 3.0177 Accuracy 0.1075\n",
      "Epoch 1 Batch 2480 Loss 3.0165 Accuracy 0.1075\n",
      "Epoch 1 Batch 2485 Loss 3.0155 Accuracy 0.1076\n",
      "Epoch 1 Batch 2490 Loss 3.0147 Accuracy 0.1077\n",
      "Epoch 1 Batch 2495 Loss 3.0139 Accuracy 0.1078\n",
      "Epoch 1 Batch 2500 Loss 3.0127 Accuracy 0.1079\n",
      "Epoch 1 Batch 2505 Loss 3.0119 Accuracy 0.1079\n",
      "Epoch 1 Batch 2510 Loss 3.0109 Accuracy 0.1080\n",
      "Epoch 1 Batch 2515 Loss 3.0100 Accuracy 0.1081\n",
      "Epoch 1 Batch 2520 Loss 3.0092 Accuracy 0.1082\n",
      "Epoch 1 Batch 2525 Loss 3.0077 Accuracy 0.1083\n",
      "Epoch 1 Batch 2530 Loss 3.0068 Accuracy 0.1083\n",
      "Epoch 1 Batch 2535 Loss 3.0060 Accuracy 0.1084\n",
      "Epoch 1 Batch 2540 Loss 3.0055 Accuracy 0.1085\n",
      "Epoch 1 Batch 2545 Loss 3.0041 Accuracy 0.1085\n",
      "Epoch 1 Batch 2550 Loss 3.0038 Accuracy 0.1086\n",
      "Epoch 1 Batch 2555 Loss 3.0027 Accuracy 0.1087\n",
      "Epoch 1 Batch 2560 Loss 3.0018 Accuracy 0.1088\n",
      "Epoch 1 Batch 2565 Loss 3.0008 Accuracy 0.1088\n",
      "Epoch 1 Batch 2570 Loss 2.9994 Accuracy 0.1089\n",
      "Epoch 1 Batch 2575 Loss 2.9984 Accuracy 0.1090\n",
      "Epoch 1 Batch 2580 Loss 2.9974 Accuracy 0.1091\n",
      "Epoch 1 Batch 2585 Loss 2.9973 Accuracy 0.1092\n",
      "Epoch 1 Batch 2590 Loss 2.9962 Accuracy 0.1093\n",
      "Epoch 1 Batch 2595 Loss 2.9951 Accuracy 0.1093\n",
      "Epoch 1 Batch 2600 Loss 2.9942 Accuracy 0.1094\n",
      "Epoch 1 Batch 2605 Loss 2.9931 Accuracy 0.1095\n",
      "Epoch 1 Batch 2610 Loss 2.9925 Accuracy 0.1096\n",
      "Epoch 1 Batch 2615 Loss 2.9916 Accuracy 0.1096\n",
      "Epoch 1 Batch 2620 Loss 2.9907 Accuracy 0.1097\n",
      "Epoch 1 Batch 2625 Loss 2.9896 Accuracy 0.1098\n",
      "Epoch 1 Batch 2630 Loss 2.9892 Accuracy 0.1099\n",
      "Epoch 1 Batch 2635 Loss 2.9884 Accuracy 0.1099\n",
      "Epoch 1 Batch 2640 Loss 2.9877 Accuracy 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 2645 Loss 2.9865 Accuracy 0.1101\n",
      "Epoch 1 Batch 2650 Loss 2.9856 Accuracy 0.1102\n",
      "Epoch 1 Batch 2655 Loss 2.9842 Accuracy 0.1102\n",
      "Epoch 1 Batch 2660 Loss 2.9831 Accuracy 0.1103\n",
      "Epoch 1 Batch 2665 Loss 2.9818 Accuracy 0.1103\n",
      "Epoch 1 Batch 2670 Loss 2.9810 Accuracy 0.1104\n",
      "Epoch 1 Batch 2675 Loss 2.9803 Accuracy 0.1105\n",
      "Epoch 1 Batch 2680 Loss 2.9793 Accuracy 0.1105\n",
      "Epoch 1 Batch 2685 Loss 2.9783 Accuracy 0.1106\n",
      "Epoch 1 Batch 2690 Loss 2.9773 Accuracy 0.1107\n",
      "Epoch 1 Batch 2695 Loss 2.9763 Accuracy 0.1107\n",
      "Epoch 1 Batch 2700 Loss 2.9752 Accuracy 0.1108\n",
      "Epoch 1 Batch 2705 Loss 2.9740 Accuracy 0.1109\n",
      "Epoch 1 Batch 2710 Loss 2.9733 Accuracy 0.1109\n",
      "Epoch 1 Batch 2715 Loss 2.9725 Accuracy 0.1110\n",
      "Epoch 1 Batch 2720 Loss 2.9718 Accuracy 0.1111\n",
      "Epoch 1 Batch 2725 Loss 2.9707 Accuracy 0.1111\n",
      "Epoch 1 Batch 2730 Loss 2.9704 Accuracy 0.1112\n",
      "Epoch 1 Batch 2735 Loss 2.9696 Accuracy 0.1113\n",
      "Epoch 1 Batch 2740 Loss 2.9686 Accuracy 0.1114\n",
      "Epoch 1 Batch 2745 Loss 2.9676 Accuracy 0.1115\n",
      "Epoch 1 Batch 2750 Loss 2.9666 Accuracy 0.1115\n",
      "Epoch 1 Batch 2755 Loss 2.9661 Accuracy 0.1116\n",
      "Epoch 1 Batch 2760 Loss 2.9648 Accuracy 0.1117\n",
      "Epoch 1 Batch 2765 Loss 2.9640 Accuracy 0.1117\n",
      "Epoch 1 Batch 2770 Loss 2.9636 Accuracy 0.1118\n",
      "Epoch 1 Batch 2775 Loss 2.9631 Accuracy 0.1119\n",
      "Epoch 1 Batch 2780 Loss 2.9623 Accuracy 0.1120\n",
      "Epoch 1 Batch 2785 Loss 2.9616 Accuracy 0.1120\n",
      "Epoch 1 Batch 2790 Loss 2.9610 Accuracy 0.1121\n",
      "Epoch 1 Batch 2795 Loss 2.9603 Accuracy 0.1122\n",
      "Epoch 1 Batch 2800 Loss 2.9595 Accuracy 0.1122\n",
      "Epoch 1 Batch 2805 Loss 2.9587 Accuracy 0.1123\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/train/ckpt-1\n",
      "Epoch 1 Loss 2.9578 Accuracy 0.1123\n",
      "Time taken for 1 epoch: 2801.515076637268 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.2326 Accuracy 0.2083\n",
      "Epoch 2 Batch 5 Loss 2.6133 Accuracy 0.1612\n",
      "Epoch 2 Batch 10 Loss 2.6756 Accuracy 0.1634\n",
      "Epoch 2 Batch 15 Loss 2.5708 Accuracy 0.1576\n",
      "Epoch 2 Batch 20 Loss 2.6181 Accuracy 0.1570\n",
      "Epoch 2 Batch 25 Loss 2.6285 Accuracy 0.1549\n",
      "Epoch 2 Batch 30 Loss 2.6292 Accuracy 0.1538\n",
      "Epoch 2 Batch 35 Loss 2.5919 Accuracy 0.1524\n",
      "Epoch 2 Batch 40 Loss 2.5676 Accuracy 0.1522\n",
      "Epoch 2 Batch 45 Loss 2.5554 Accuracy 0.1516\n",
      "Epoch 2 Batch 50 Loss 2.5511 Accuracy 0.1498\n",
      "Epoch 2 Batch 55 Loss 2.5416 Accuracy 0.1493\n",
      "Epoch 2 Batch 60 Loss 2.5499 Accuracy 0.1486\n",
      "Epoch 2 Batch 65 Loss 2.5310 Accuracy 0.1490\n",
      "Epoch 2 Batch 70 Loss 2.5444 Accuracy 0.1506\n",
      "Epoch 2 Batch 75 Loss 2.5391 Accuracy 0.1505\n",
      "Epoch 2 Batch 80 Loss 2.5435 Accuracy 0.1511\n",
      "Epoch 2 Batch 85 Loss 2.5362 Accuracy 0.1510\n",
      "Epoch 2 Batch 90 Loss 2.5421 Accuracy 0.1509\n",
      "Epoch 2 Batch 95 Loss 2.5394 Accuracy 0.1513\n",
      "Epoch 2 Batch 100 Loss 2.5502 Accuracy 0.1518\n",
      "Epoch 2 Batch 105 Loss 2.5542 Accuracy 0.1519\n",
      "Epoch 2 Batch 110 Loss 2.5542 Accuracy 0.1524\n",
      "Epoch 2 Batch 115 Loss 2.5496 Accuracy 0.1524\n",
      "Epoch 2 Batch 120 Loss 2.5598 Accuracy 0.1527\n",
      "Epoch 2 Batch 125 Loss 2.5572 Accuracy 0.1529\n",
      "Epoch 2 Batch 130 Loss 2.5623 Accuracy 0.1533\n",
      "Epoch 2 Batch 135 Loss 2.5551 Accuracy 0.1530\n",
      "Epoch 2 Batch 140 Loss 2.5592 Accuracy 0.1527\n",
      "Epoch 2 Batch 145 Loss 2.5538 Accuracy 0.1524\n",
      "Epoch 2 Batch 150 Loss 2.5560 Accuracy 0.1524\n",
      "Epoch 2 Batch 155 Loss 2.5568 Accuracy 0.1523\n",
      "Epoch 2 Batch 160 Loss 2.5603 Accuracy 0.1524\n",
      "Epoch 2 Batch 165 Loss 2.5550 Accuracy 0.1523\n",
      "Epoch 2 Batch 170 Loss 2.5526 Accuracy 0.1522\n",
      "Epoch 2 Batch 175 Loss 2.5496 Accuracy 0.1522\n",
      "Epoch 2 Batch 180 Loss 2.5442 Accuracy 0.1519\n",
      "Epoch 2 Batch 185 Loss 2.5454 Accuracy 0.1522\n",
      "Epoch 2 Batch 190 Loss 2.5501 Accuracy 0.1524\n",
      "Epoch 2 Batch 195 Loss 2.5527 Accuracy 0.1527\n",
      "Epoch 2 Batch 200 Loss 2.5500 Accuracy 0.1529\n",
      "Epoch 2 Batch 205 Loss 2.5486 Accuracy 0.1528\n",
      "Epoch 2 Batch 210 Loss 2.5454 Accuracy 0.1529\n",
      "Epoch 2 Batch 215 Loss 2.5528 Accuracy 0.1533\n",
      "Epoch 2 Batch 220 Loss 2.5533 Accuracy 0.1534\n",
      "Epoch 2 Batch 225 Loss 2.5504 Accuracy 0.1535\n",
      "Epoch 2 Batch 230 Loss 2.5473 Accuracy 0.1532\n",
      "Epoch 2 Batch 235 Loss 2.5470 Accuracy 0.1530\n",
      "Epoch 2 Batch 240 Loss 2.5425 Accuracy 0.1528\n",
      "Epoch 2 Batch 245 Loss 2.5371 Accuracy 0.1529\n",
      "Epoch 2 Batch 250 Loss 2.5375 Accuracy 0.1531\n",
      "Epoch 2 Batch 255 Loss 2.5348 Accuracy 0.1527\n",
      "Epoch 2 Batch 260 Loss 2.5361 Accuracy 0.1528\n",
      "Epoch 2 Batch 265 Loss 2.5344 Accuracy 0.1529\n",
      "Epoch 2 Batch 270 Loss 2.5277 Accuracy 0.1529\n",
      "Epoch 2 Batch 275 Loss 2.5269 Accuracy 0.1531\n",
      "Epoch 2 Batch 280 Loss 2.5276 Accuracy 0.1531\n",
      "Epoch 2 Batch 285 Loss 2.5258 Accuracy 0.1529\n",
      "Epoch 2 Batch 290 Loss 2.5261 Accuracy 0.1530\n",
      "Epoch 2 Batch 295 Loss 2.5270 Accuracy 0.1530\n",
      "Epoch 2 Batch 300 Loss 2.5341 Accuracy 0.1532\n",
      "Epoch 2 Batch 305 Loss 2.5365 Accuracy 0.1531\n",
      "Epoch 2 Batch 310 Loss 2.5329 Accuracy 0.1530\n",
      "Epoch 2 Batch 315 Loss 2.5314 Accuracy 0.1530\n",
      "Epoch 2 Batch 320 Loss 2.5317 Accuracy 0.1529\n",
      "Epoch 2 Batch 325 Loss 2.5350 Accuracy 0.1531\n",
      "Epoch 2 Batch 330 Loss 2.5299 Accuracy 0.1533\n",
      "Epoch 2 Batch 335 Loss 2.5250 Accuracy 0.1530\n",
      "Epoch 2 Batch 340 Loss 2.5259 Accuracy 0.1532\n",
      "Epoch 2 Batch 345 Loss 2.5252 Accuracy 0.1534\n",
      "Epoch 2 Batch 350 Loss 2.5240 Accuracy 0.1535\n",
      "Epoch 2 Batch 355 Loss 2.5277 Accuracy 0.1537\n",
      "Epoch 2 Batch 360 Loss 2.5262 Accuracy 0.1537\n",
      "Epoch 2 Batch 365 Loss 2.5273 Accuracy 0.1540\n",
      "Epoch 2 Batch 370 Loss 2.5276 Accuracy 0.1540\n",
      "Epoch 2 Batch 375 Loss 2.5273 Accuracy 0.1538\n",
      "Epoch 2 Batch 380 Loss 2.5255 Accuracy 0.1537\n",
      "Epoch 2 Batch 385 Loss 2.5242 Accuracy 0.1537\n",
      "Epoch 2 Batch 390 Loss 2.5241 Accuracy 0.1538\n",
      "Epoch 2 Batch 395 Loss 2.5243 Accuracy 0.1536\n",
      "Epoch 2 Batch 400 Loss 2.5241 Accuracy 0.1535\n",
      "Epoch 2 Batch 405 Loss 2.5252 Accuracy 0.1536\n",
      "Epoch 2 Batch 410 Loss 2.5272 Accuracy 0.1538\n",
      "Epoch 2 Batch 415 Loss 2.5272 Accuracy 0.1539\n",
      "Epoch 2 Batch 420 Loss 2.5304 Accuracy 0.1539\n",
      "Epoch 2 Batch 425 Loss 2.5302 Accuracy 0.1538\n",
      "Epoch 2 Batch 430 Loss 2.5285 Accuracy 0.1539\n",
      "Epoch 2 Batch 435 Loss 2.5295 Accuracy 0.1539\n",
      "Epoch 2 Batch 440 Loss 2.5256 Accuracy 0.1539\n",
      "Epoch 2 Batch 445 Loss 2.5274 Accuracy 0.1539\n",
      "Epoch 2 Batch 450 Loss 2.5283 Accuracy 0.1538\n",
      "Epoch 2 Batch 455 Loss 2.5265 Accuracy 0.1537\n",
      "Epoch 2 Batch 460 Loss 2.5270 Accuracy 0.1539\n",
      "Epoch 2 Batch 465 Loss 2.5273 Accuracy 0.1539\n",
      "Epoch 2 Batch 470 Loss 2.5253 Accuracy 0.1539\n",
      "Epoch 2 Batch 475 Loss 2.5240 Accuracy 0.1539\n",
      "Epoch 2 Batch 480 Loss 2.5245 Accuracy 0.1539\n",
      "Epoch 2 Batch 485 Loss 2.5241 Accuracy 0.1540\n",
      "Epoch 2 Batch 490 Loss 2.5244 Accuracy 0.1539\n",
      "Epoch 2 Batch 495 Loss 2.5228 Accuracy 0.1538\n",
      "Epoch 2 Batch 500 Loss 2.5206 Accuracy 0.1537\n",
      "Epoch 2 Batch 505 Loss 2.5205 Accuracy 0.1537\n",
      "Epoch 2 Batch 510 Loss 2.5172 Accuracy 0.1537\n",
      "Epoch 2 Batch 515 Loss 2.5161 Accuracy 0.1537\n",
      "Epoch 2 Batch 520 Loss 2.5141 Accuracy 0.1537\n",
      "Epoch 2 Batch 525 Loss 2.5136 Accuracy 0.1536\n",
      "Epoch 2 Batch 530 Loss 2.5122 Accuracy 0.1536\n",
      "Epoch 2 Batch 535 Loss 2.5119 Accuracy 0.1535\n",
      "Epoch 2 Batch 540 Loss 2.5086 Accuracy 0.1534\n",
      "Epoch 2 Batch 545 Loss 2.5079 Accuracy 0.1534\n",
      "Epoch 2 Batch 550 Loss 2.5082 Accuracy 0.1534\n",
      "Epoch 2 Batch 555 Loss 2.5060 Accuracy 0.1533\n",
      "Epoch 2 Batch 560 Loss 2.5061 Accuracy 0.1535\n",
      "Epoch 2 Batch 565 Loss 2.5079 Accuracy 0.1536\n",
      "Epoch 2 Batch 570 Loss 2.5094 Accuracy 0.1535\n",
      "Epoch 2 Batch 575 Loss 2.5093 Accuracy 0.1535\n",
      "Epoch 2 Batch 580 Loss 2.5082 Accuracy 0.1535\n",
      "Epoch 2 Batch 585 Loss 2.5086 Accuracy 0.1535\n",
      "Epoch 2 Batch 590 Loss 2.5081 Accuracy 0.1534\n",
      "Epoch 2 Batch 595 Loss 2.5058 Accuracy 0.1533\n",
      "Epoch 2 Batch 600 Loss 2.5048 Accuracy 0.1534\n",
      "Epoch 2 Batch 605 Loss 2.5043 Accuracy 0.1534\n",
      "Epoch 2 Batch 610 Loss 2.5038 Accuracy 0.1534\n",
      "Epoch 2 Batch 615 Loss 2.5035 Accuracy 0.1534\n",
      "Epoch 2 Batch 620 Loss 2.5039 Accuracy 0.1534\n",
      "Epoch 2 Batch 625 Loss 2.5039 Accuracy 0.1534\n",
      "Epoch 2 Batch 630 Loss 2.5039 Accuracy 0.1534\n",
      "Epoch 2 Batch 635 Loss 2.5035 Accuracy 0.1535\n",
      "Epoch 2 Batch 640 Loss 2.5038 Accuracy 0.1534\n",
      "Epoch 2 Batch 645 Loss 2.5035 Accuracy 0.1534\n",
      "Epoch 2 Batch 650 Loss 2.5025 Accuracy 0.1533\n",
      "Epoch 2 Batch 655 Loss 2.5012 Accuracy 0.1533\n",
      "Epoch 2 Batch 660 Loss 2.5013 Accuracy 0.1533\n",
      "Epoch 2 Batch 665 Loss 2.5014 Accuracy 0.1533\n",
      "Epoch 2 Batch 670 Loss 2.5006 Accuracy 0.1533\n",
      "Epoch 2 Batch 675 Loss 2.4993 Accuracy 0.1532\n",
      "Epoch 2 Batch 680 Loss 2.4995 Accuracy 0.1531\n",
      "Epoch 2 Batch 685 Loss 2.4988 Accuracy 0.1530\n",
      "Epoch 2 Batch 690 Loss 2.4975 Accuracy 0.1530\n",
      "Epoch 2 Batch 695 Loss 2.4954 Accuracy 0.1529\n",
      "Epoch 2 Batch 700 Loss 2.4936 Accuracy 0.1527\n",
      "Epoch 2 Batch 705 Loss 2.4926 Accuracy 0.1527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 710 Loss 2.4925 Accuracy 0.1528\n",
      "Epoch 2 Batch 715 Loss 2.4920 Accuracy 0.1528\n",
      "Epoch 2 Batch 720 Loss 2.4913 Accuracy 0.1528\n",
      "Epoch 2 Batch 725 Loss 2.4902 Accuracy 0.1527\n",
      "Epoch 2 Batch 730 Loss 2.4904 Accuracy 0.1527\n",
      "Epoch 2 Batch 735 Loss 2.4903 Accuracy 0.1527\n",
      "Epoch 2 Batch 740 Loss 2.4893 Accuracy 0.1527\n",
      "Epoch 2 Batch 745 Loss 2.4882 Accuracy 0.1527\n",
      "Epoch 2 Batch 750 Loss 2.4889 Accuracy 0.1528\n",
      "Epoch 2 Batch 755 Loss 2.4893 Accuracy 0.1528\n",
      "Epoch 2 Batch 760 Loss 2.4891 Accuracy 0.1527\n",
      "Epoch 2 Batch 765 Loss 2.4876 Accuracy 0.1528\n",
      "Epoch 2 Batch 770 Loss 2.4868 Accuracy 0.1528\n",
      "Epoch 2 Batch 775 Loss 2.4877 Accuracy 0.1528\n",
      "Epoch 2 Batch 780 Loss 2.4888 Accuracy 0.1529\n",
      "Epoch 2 Batch 785 Loss 2.4897 Accuracy 0.1529\n",
      "Epoch 2 Batch 790 Loss 2.4888 Accuracy 0.1530\n",
      "Epoch 2 Batch 795 Loss 2.4864 Accuracy 0.1530\n",
      "Epoch 2 Batch 800 Loss 2.4868 Accuracy 0.1531\n",
      "Epoch 2 Batch 805 Loss 2.4860 Accuracy 0.1531\n",
      "Epoch 2 Batch 810 Loss 2.4878 Accuracy 0.1531\n",
      "Epoch 2 Batch 815 Loss 2.4875 Accuracy 0.1531\n",
      "Epoch 2 Batch 820 Loss 2.4857 Accuracy 0.1530\n",
      "Epoch 2 Batch 825 Loss 2.4853 Accuracy 0.1531\n",
      "Epoch 2 Batch 830 Loss 2.4835 Accuracy 0.1531\n",
      "Epoch 2 Batch 835 Loss 2.4848 Accuracy 0.1530\n",
      "Epoch 2 Batch 840 Loss 2.4843 Accuracy 0.1531\n",
      "Epoch 2 Batch 845 Loss 2.4840 Accuracy 0.1531\n",
      "Epoch 2 Batch 850 Loss 2.4845 Accuracy 0.1530\n",
      "Epoch 2 Batch 855 Loss 2.4839 Accuracy 0.1530\n",
      "Epoch 2 Batch 860 Loss 2.4845 Accuracy 0.1530\n",
      "Epoch 2 Batch 865 Loss 2.4839 Accuracy 0.1530\n",
      "Epoch 2 Batch 870 Loss 2.4837 Accuracy 0.1531\n",
      "Epoch 2 Batch 875 Loss 2.4836 Accuracy 0.1531\n",
      "Epoch 2 Batch 880 Loss 2.4839 Accuracy 0.1531\n",
      "Epoch 2 Batch 885 Loss 2.4845 Accuracy 0.1531\n",
      "Epoch 2 Batch 890 Loss 2.4843 Accuracy 0.1532\n",
      "Epoch 2 Batch 895 Loss 2.4840 Accuracy 0.1531\n",
      "Epoch 2 Batch 900 Loss 2.4839 Accuracy 0.1532\n",
      "Epoch 2 Batch 905 Loss 2.4847 Accuracy 0.1532\n",
      "Epoch 2 Batch 910 Loss 2.4837 Accuracy 0.1532\n",
      "Epoch 2 Batch 915 Loss 2.4848 Accuracy 0.1532\n",
      "Epoch 2 Batch 920 Loss 2.4838 Accuracy 0.1532\n",
      "Epoch 2 Batch 925 Loss 2.4826 Accuracy 0.1533\n",
      "Epoch 2 Batch 930 Loss 2.4828 Accuracy 0.1533\n",
      "Epoch 2 Batch 935 Loss 2.4812 Accuracy 0.1532\n",
      "Epoch 2 Batch 940 Loss 2.4821 Accuracy 0.1533\n",
      "Epoch 2 Batch 945 Loss 2.4823 Accuracy 0.1533\n",
      "Epoch 2 Batch 950 Loss 2.4824 Accuracy 0.1533\n",
      "Epoch 2 Batch 955 Loss 2.4817 Accuracy 0.1533\n",
      "Epoch 2 Batch 960 Loss 2.4817 Accuracy 0.1533\n",
      "Epoch 2 Batch 965 Loss 2.4814 Accuracy 0.1534\n",
      "Epoch 2 Batch 970 Loss 2.4807 Accuracy 0.1534\n",
      "Epoch 2 Batch 975 Loss 2.4792 Accuracy 0.1533\n",
      "Epoch 2 Batch 980 Loss 2.4790 Accuracy 0.1534\n",
      "Epoch 2 Batch 985 Loss 2.4775 Accuracy 0.1533\n",
      "Epoch 2 Batch 990 Loss 2.4783 Accuracy 0.1533\n",
      "Epoch 2 Batch 995 Loss 2.4774 Accuracy 0.1534\n",
      "Epoch 2 Batch 1000 Loss 2.4786 Accuracy 0.1534\n",
      "Epoch 2 Batch 1005 Loss 2.4778 Accuracy 0.1534\n",
      "Epoch 2 Batch 1010 Loss 2.4776 Accuracy 0.1534\n",
      "Epoch 2 Batch 1015 Loss 2.4776 Accuracy 0.1534\n",
      "Epoch 2 Batch 1020 Loss 2.4774 Accuracy 0.1535\n",
      "Epoch 2 Batch 1025 Loss 2.4772 Accuracy 0.1534\n",
      "Epoch 2 Batch 1030 Loss 2.4776 Accuracy 0.1535\n",
      "Epoch 2 Batch 1035 Loss 2.4778 Accuracy 0.1537\n",
      "Epoch 2 Batch 1040 Loss 2.4785 Accuracy 0.1537\n",
      "Epoch 2 Batch 1045 Loss 2.4792 Accuracy 0.1537\n",
      "Epoch 2 Batch 1050 Loss 2.4796 Accuracy 0.1537\n",
      "Epoch 2 Batch 1055 Loss 2.4790 Accuracy 0.1537\n",
      "Epoch 2 Batch 1060 Loss 2.4785 Accuracy 0.1537\n",
      "Epoch 2 Batch 1065 Loss 2.4781 Accuracy 0.1537\n",
      "Epoch 2 Batch 1070 Loss 2.4784 Accuracy 0.1538\n",
      "Epoch 2 Batch 1075 Loss 2.4789 Accuracy 0.1538\n",
      "Epoch 2 Batch 1080 Loss 2.4785 Accuracy 0.1537\n",
      "Epoch 2 Batch 1085 Loss 2.4784 Accuracy 0.1537\n",
      "Epoch 2 Batch 1090 Loss 2.4776 Accuracy 0.1537\n",
      "Epoch 2 Batch 1095 Loss 2.4773 Accuracy 0.1537\n",
      "Epoch 2 Batch 1100 Loss 2.4776 Accuracy 0.1537\n",
      "Epoch 2 Batch 1105 Loss 2.4775 Accuracy 0.1538\n",
      "Epoch 2 Batch 1110 Loss 2.4778 Accuracy 0.1539\n",
      "Epoch 2 Batch 1115 Loss 2.4772 Accuracy 0.1539\n",
      "Epoch 2 Batch 1120 Loss 2.4765 Accuracy 0.1538\n",
      "Epoch 2 Batch 1125 Loss 2.4766 Accuracy 0.1539\n",
      "Epoch 2 Batch 1130 Loss 2.4766 Accuracy 0.1539\n",
      "Epoch 2 Batch 1135 Loss 2.4761 Accuracy 0.1539\n",
      "Epoch 2 Batch 1140 Loss 2.4765 Accuracy 0.1539\n",
      "Epoch 2 Batch 1145 Loss 2.4772 Accuracy 0.1540\n",
      "Epoch 2 Batch 1150 Loss 2.4777 Accuracy 0.1540\n",
      "Epoch 2 Batch 1155 Loss 2.4781 Accuracy 0.1540\n",
      "Epoch 2 Batch 1160 Loss 2.4785 Accuracy 0.1541\n",
      "Epoch 2 Batch 1165 Loss 2.4779 Accuracy 0.1540\n",
      "Epoch 2 Batch 1170 Loss 2.4775 Accuracy 0.1540\n",
      "Epoch 2 Batch 1175 Loss 2.4780 Accuracy 0.1540\n",
      "Epoch 2 Batch 1180 Loss 2.4776 Accuracy 0.1540\n",
      "Epoch 2 Batch 1185 Loss 2.4773 Accuracy 0.1540\n",
      "Epoch 2 Batch 1190 Loss 2.4777 Accuracy 0.1540\n",
      "Epoch 2 Batch 1195 Loss 2.4771 Accuracy 0.1541\n",
      "Epoch 2 Batch 1200 Loss 2.4775 Accuracy 0.1541\n",
      "Epoch 2 Batch 1205 Loss 2.4777 Accuracy 0.1541\n",
      "Epoch 2 Batch 1210 Loss 2.4763 Accuracy 0.1541\n",
      "Epoch 2 Batch 1215 Loss 2.4755 Accuracy 0.1541\n",
      "Epoch 2 Batch 1220 Loss 2.4749 Accuracy 0.1541\n",
      "Epoch 2 Batch 1225 Loss 2.4751 Accuracy 0.1541\n",
      "Epoch 2 Batch 1230 Loss 2.4751 Accuracy 0.1541\n",
      "Epoch 2 Batch 1235 Loss 2.4754 Accuracy 0.1541\n",
      "Epoch 2 Batch 1240 Loss 2.4749 Accuracy 0.1541\n",
      "Epoch 2 Batch 1245 Loss 2.4745 Accuracy 0.1542\n",
      "Epoch 2 Batch 1250 Loss 2.4741 Accuracy 0.1541\n",
      "Epoch 2 Batch 1255 Loss 2.4737 Accuracy 0.1542\n",
      "Epoch 2 Batch 1260 Loss 2.4739 Accuracy 0.1542\n",
      "Epoch 2 Batch 1265 Loss 2.4732 Accuracy 0.1543\n",
      "Epoch 2 Batch 1270 Loss 2.4729 Accuracy 0.1543\n",
      "Epoch 2 Batch 1275 Loss 2.4725 Accuracy 0.1543\n",
      "Epoch 2 Batch 1280 Loss 2.4718 Accuracy 0.1542\n",
      "Epoch 2 Batch 1285 Loss 2.4718 Accuracy 0.1542\n",
      "Epoch 2 Batch 1290 Loss 2.4708 Accuracy 0.1542\n",
      "Epoch 2 Batch 1295 Loss 2.4707 Accuracy 0.1542\n",
      "Epoch 2 Batch 1300 Loss 2.4693 Accuracy 0.1543\n",
      "Epoch 2 Batch 1305 Loss 2.4698 Accuracy 0.1543\n",
      "Epoch 2 Batch 1310 Loss 2.4697 Accuracy 0.1543\n",
      "Epoch 2 Batch 1315 Loss 2.4695 Accuracy 0.1543\n",
      "Epoch 2 Batch 1320 Loss 2.4697 Accuracy 0.1544\n",
      "Epoch 2 Batch 1325 Loss 2.4684 Accuracy 0.1544\n",
      "Epoch 2 Batch 1330 Loss 2.4682 Accuracy 0.1544\n",
      "Epoch 2 Batch 1335 Loss 2.4692 Accuracy 0.1544\n",
      "Epoch 2 Batch 1340 Loss 2.4691 Accuracy 0.1544\n",
      "Epoch 2 Batch 1345 Loss 2.4684 Accuracy 0.1544\n",
      "Epoch 2 Batch 1350 Loss 2.4683 Accuracy 0.1544\n",
      "Epoch 2 Batch 1355 Loss 2.4680 Accuracy 0.1544\n",
      "Epoch 2 Batch 1360 Loss 2.4677 Accuracy 0.1544\n",
      "Epoch 2 Batch 1365 Loss 2.4682 Accuracy 0.1544\n",
      "Epoch 2 Batch 1370 Loss 2.4673 Accuracy 0.1544\n",
      "Epoch 2 Batch 1375 Loss 2.4678 Accuracy 0.1544\n",
      "Epoch 2 Batch 1380 Loss 2.4676 Accuracy 0.1545\n",
      "Epoch 2 Batch 1385 Loss 2.4674 Accuracy 0.1545\n",
      "Epoch 2 Batch 1390 Loss 2.4675 Accuracy 0.1546\n",
      "Epoch 2 Batch 1395 Loss 2.4678 Accuracy 0.1546\n",
      "Epoch 2 Batch 1400 Loss 2.4692 Accuracy 0.1547\n",
      "Epoch 2 Batch 1405 Loss 2.4691 Accuracy 0.1547\n",
      "Epoch 2 Batch 1410 Loss 2.4692 Accuracy 0.1548\n",
      "Epoch 2 Batch 1415 Loss 2.4694 Accuracy 0.1548\n",
      "Epoch 2 Batch 1420 Loss 2.4697 Accuracy 0.1548\n",
      "Epoch 2 Batch 1425 Loss 2.4692 Accuracy 0.1548\n",
      "Epoch 2 Batch 1430 Loss 2.4696 Accuracy 0.1548\n",
      "Epoch 2 Batch 1435 Loss 2.4700 Accuracy 0.1548\n",
      "Epoch 2 Batch 1440 Loss 2.4695 Accuracy 0.1548\n",
      "Epoch 2 Batch 1445 Loss 2.4691 Accuracy 0.1548\n",
      "Epoch 2 Batch 1450 Loss 2.4699 Accuracy 0.1549\n",
      "Epoch 2 Batch 1455 Loss 2.4695 Accuracy 0.1549\n",
      "Epoch 2 Batch 1460 Loss 2.4684 Accuracy 0.1549\n",
      "Epoch 2 Batch 1465 Loss 2.4687 Accuracy 0.1549\n",
      "Epoch 2 Batch 1470 Loss 2.4687 Accuracy 0.1549\n",
      "Epoch 2 Batch 1475 Loss 2.4689 Accuracy 0.1550\n",
      "Epoch 2 Batch 1480 Loss 2.4689 Accuracy 0.1550\n",
      "Epoch 2 Batch 1485 Loss 2.4688 Accuracy 0.1550\n",
      "Epoch 2 Batch 1490 Loss 2.4691 Accuracy 0.1551\n",
      "Epoch 2 Batch 1495 Loss 2.4692 Accuracy 0.1551\n",
      "Epoch 2 Batch 1500 Loss 2.4693 Accuracy 0.1551\n",
      "Epoch 2 Batch 1505 Loss 2.4690 Accuracy 0.1551\n",
      "Epoch 2 Batch 1510 Loss 2.4691 Accuracy 0.1552\n",
      "Epoch 2 Batch 1515 Loss 2.4692 Accuracy 0.1552\n",
      "Epoch 2 Batch 1520 Loss 2.4700 Accuracy 0.1552\n",
      "Epoch 2 Batch 1525 Loss 2.4697 Accuracy 0.1552\n",
      "Epoch 2 Batch 1530 Loss 2.4694 Accuracy 0.1553\n",
      "Epoch 2 Batch 1535 Loss 2.4690 Accuracy 0.1553\n",
      "Epoch 2 Batch 1540 Loss 2.4680 Accuracy 0.1552\n",
      "Epoch 2 Batch 1545 Loss 2.4682 Accuracy 0.1553\n",
      "Epoch 2 Batch 1550 Loss 2.4679 Accuracy 0.1553\n",
      "Epoch 2 Batch 1555 Loss 2.4678 Accuracy 0.1553\n",
      "Epoch 2 Batch 1560 Loss 2.4679 Accuracy 0.1553\n",
      "Epoch 2 Batch 1565 Loss 2.4688 Accuracy 0.1553\n",
      "Epoch 2 Batch 1570 Loss 2.4687 Accuracy 0.1553\n",
      "Epoch 2 Batch 1575 Loss 2.4686 Accuracy 0.1553\n",
      "Epoch 2 Batch 1580 Loss 2.4687 Accuracy 0.1554\n",
      "Epoch 2 Batch 1585 Loss 2.4682 Accuracy 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 1590 Loss 2.4679 Accuracy 0.1554\n",
      "Epoch 2 Batch 1595 Loss 2.4678 Accuracy 0.1554\n",
      "Epoch 2 Batch 1600 Loss 2.4671 Accuracy 0.1554\n",
      "Epoch 2 Batch 1605 Loss 2.4664 Accuracy 0.1555\n",
      "Epoch 2 Batch 1610 Loss 2.4663 Accuracy 0.1555\n",
      "Epoch 2 Batch 1615 Loss 2.4669 Accuracy 0.1556\n",
      "Epoch 2 Batch 1620 Loss 2.4657 Accuracy 0.1556\n",
      "Epoch 2 Batch 1625 Loss 2.4649 Accuracy 0.1556\n",
      "Epoch 2 Batch 1630 Loss 2.4650 Accuracy 0.1556\n",
      "Epoch 2 Batch 1635 Loss 2.4651 Accuracy 0.1556\n",
      "Epoch 2 Batch 1640 Loss 2.4650 Accuracy 0.1556\n",
      "Epoch 2 Batch 1645 Loss 2.4646 Accuracy 0.1556\n",
      "Epoch 2 Batch 1650 Loss 2.4643 Accuracy 0.1557\n",
      "Epoch 2 Batch 1655 Loss 2.4647 Accuracy 0.1557\n",
      "Epoch 2 Batch 1660 Loss 2.4648 Accuracy 0.1557\n",
      "Epoch 2 Batch 1665 Loss 2.4642 Accuracy 0.1557\n",
      "Epoch 2 Batch 1670 Loss 2.4641 Accuracy 0.1557\n",
      "Epoch 2 Batch 1675 Loss 2.4640 Accuracy 0.1557\n",
      "Epoch 2 Batch 1680 Loss 2.4632 Accuracy 0.1557\n",
      "Epoch 2 Batch 1685 Loss 2.4632 Accuracy 0.1558\n",
      "Epoch 2 Batch 1690 Loss 2.4636 Accuracy 0.1558\n",
      "Epoch 2 Batch 1695 Loss 2.4629 Accuracy 0.1558\n",
      "Epoch 2 Batch 1700 Loss 2.4633 Accuracy 0.1558\n",
      "Epoch 2 Batch 1705 Loss 2.4618 Accuracy 0.1558\n",
      "Epoch 2 Batch 1710 Loss 2.4620 Accuracy 0.1559\n",
      "Epoch 2 Batch 1715 Loss 2.4610 Accuracy 0.1559\n",
      "Epoch 2 Batch 1720 Loss 2.4602 Accuracy 0.1559\n",
      "Epoch 2 Batch 1725 Loss 2.4593 Accuracy 0.1559\n",
      "Epoch 2 Batch 1730 Loss 2.4594 Accuracy 0.1560\n",
      "Epoch 2 Batch 1735 Loss 2.4595 Accuracy 0.1560\n",
      "Epoch 2 Batch 1740 Loss 2.4591 Accuracy 0.1560\n",
      "Epoch 2 Batch 1745 Loss 2.4592 Accuracy 0.1560\n",
      "Epoch 2 Batch 1750 Loss 2.4589 Accuracy 0.1560\n",
      "Epoch 2 Batch 1755 Loss 2.4585 Accuracy 0.1560\n",
      "Epoch 2 Batch 1760 Loss 2.4580 Accuracy 0.1560\n",
      "Epoch 2 Batch 1765 Loss 2.4579 Accuracy 0.1560\n",
      "Epoch 2 Batch 1770 Loss 2.4579 Accuracy 0.1560\n",
      "Epoch 2 Batch 1775 Loss 2.4569 Accuracy 0.1560\n",
      "Epoch 2 Batch 1780 Loss 2.4562 Accuracy 0.1560\n",
      "Epoch 2 Batch 1785 Loss 2.4554 Accuracy 0.1560\n",
      "Epoch 2 Batch 1790 Loss 2.4545 Accuracy 0.1560\n",
      "Epoch 2 Batch 1795 Loss 2.4539 Accuracy 0.1560\n",
      "Epoch 2 Batch 1800 Loss 2.4543 Accuracy 0.1560\n",
      "Epoch 2 Batch 1805 Loss 2.4541 Accuracy 0.1560\n",
      "Epoch 2 Batch 1810 Loss 2.4539 Accuracy 0.1561\n",
      "Epoch 2 Batch 1815 Loss 2.4543 Accuracy 0.1561\n",
      "Epoch 2 Batch 1820 Loss 2.4539 Accuracy 0.1561\n",
      "Epoch 2 Batch 1825 Loss 2.4543 Accuracy 0.1562\n",
      "Epoch 2 Batch 1830 Loss 2.4536 Accuracy 0.1561\n",
      "Epoch 2 Batch 1835 Loss 2.4530 Accuracy 0.1562\n",
      "Epoch 2 Batch 1840 Loss 2.4523 Accuracy 0.1562\n",
      "Epoch 2 Batch 1845 Loss 2.4524 Accuracy 0.1562\n",
      "Epoch 2 Batch 1850 Loss 2.4517 Accuracy 0.1562\n",
      "Epoch 2 Batch 1855 Loss 2.4516 Accuracy 0.1562\n",
      "Epoch 2 Batch 1860 Loss 2.4513 Accuracy 0.1562\n",
      "Epoch 2 Batch 1865 Loss 2.4510 Accuracy 0.1563\n",
      "Epoch 2 Batch 1870 Loss 2.4507 Accuracy 0.1563\n",
      "Epoch 2 Batch 1875 Loss 2.4505 Accuracy 0.1563\n",
      "Epoch 2 Batch 1880 Loss 2.4503 Accuracy 0.1563\n",
      "Epoch 2 Batch 1885 Loss 2.4501 Accuracy 0.1563\n",
      "Epoch 2 Batch 1890 Loss 2.4498 Accuracy 0.1563\n",
      "Epoch 2 Batch 1895 Loss 2.4492 Accuracy 0.1563\n",
      "Epoch 2 Batch 1900 Loss 2.4486 Accuracy 0.1562\n",
      "Epoch 2 Batch 1905 Loss 2.4478 Accuracy 0.1562\n",
      "Epoch 2 Batch 1910 Loss 2.4479 Accuracy 0.1563\n",
      "Epoch 2 Batch 1915 Loss 2.4479 Accuracy 0.1563\n",
      "Epoch 2 Batch 1920 Loss 2.4480 Accuracy 0.1563\n",
      "Epoch 2 Batch 1925 Loss 2.4482 Accuracy 0.1563\n",
      "Epoch 2 Batch 1930 Loss 2.4482 Accuracy 0.1563\n",
      "Epoch 2 Batch 1935 Loss 2.4482 Accuracy 0.1564\n",
      "Epoch 2 Batch 1940 Loss 2.4478 Accuracy 0.1564\n",
      "Epoch 2 Batch 1945 Loss 2.4473 Accuracy 0.1564\n",
      "Epoch 2 Batch 1950 Loss 2.4471 Accuracy 0.1564\n",
      "Epoch 2 Batch 1955 Loss 2.4466 Accuracy 0.1564\n",
      "Epoch 2 Batch 1960 Loss 2.4460 Accuracy 0.1564\n",
      "Epoch 2 Batch 1965 Loss 2.4460 Accuracy 0.1564\n",
      "Epoch 2 Batch 1970 Loss 2.4460 Accuracy 0.1564\n",
      "Epoch 2 Batch 1975 Loss 2.4458 Accuracy 0.1565\n",
      "Epoch 2 Batch 1980 Loss 2.4459 Accuracy 0.1566\n",
      "Epoch 2 Batch 1985 Loss 2.4459 Accuracy 0.1566\n",
      "Epoch 2 Batch 1990 Loss 2.4457 Accuracy 0.1566\n",
      "Epoch 2 Batch 1995 Loss 2.4451 Accuracy 0.1566\n",
      "Epoch 2 Batch 2000 Loss 2.4449 Accuracy 0.1566\n",
      "Epoch 2 Batch 2005 Loss 2.4448 Accuracy 0.1566\n",
      "Epoch 2 Batch 2010 Loss 2.4444 Accuracy 0.1566\n",
      "Epoch 2 Batch 2015 Loss 2.4445 Accuracy 0.1567\n",
      "Epoch 2 Batch 2020 Loss 2.4439 Accuracy 0.1567\n",
      "Epoch 2 Batch 2025 Loss 2.4443 Accuracy 0.1567\n",
      "Epoch 2 Batch 2030 Loss 2.4445 Accuracy 0.1567\n",
      "Epoch 2 Batch 2035 Loss 2.4442 Accuracy 0.1567\n",
      "Epoch 2 Batch 2040 Loss 2.4438 Accuracy 0.1567\n",
      "Epoch 2 Batch 2045 Loss 2.4432 Accuracy 0.1567\n",
      "Epoch 2 Batch 2050 Loss 2.4429 Accuracy 0.1567\n",
      "Epoch 2 Batch 2055 Loss 2.4429 Accuracy 0.1568\n",
      "Epoch 2 Batch 2060 Loss 2.4429 Accuracy 0.1568\n",
      "Epoch 2 Batch 2065 Loss 2.4434 Accuracy 0.1569\n",
      "Epoch 2 Batch 2070 Loss 2.4434 Accuracy 0.1569\n",
      "Epoch 2 Batch 2075 Loss 2.4433 Accuracy 0.1570\n",
      "Epoch 2 Batch 2080 Loss 2.4424 Accuracy 0.1569\n",
      "Epoch 2 Batch 2085 Loss 2.4419 Accuracy 0.1569\n",
      "Epoch 2 Batch 2090 Loss 2.4421 Accuracy 0.1570\n",
      "Epoch 2 Batch 2095 Loss 2.4421 Accuracy 0.1570\n",
      "Epoch 2 Batch 2100 Loss 2.4421 Accuracy 0.1570\n",
      "Epoch 2 Batch 2105 Loss 2.4416 Accuracy 0.1570\n",
      "Epoch 2 Batch 2110 Loss 2.4414 Accuracy 0.1571\n",
      "Epoch 2 Batch 2115 Loss 2.4413 Accuracy 0.1571\n",
      "Epoch 2 Batch 2120 Loss 2.4412 Accuracy 0.1571\n",
      "Epoch 2 Batch 2125 Loss 2.4406 Accuracy 0.1571\n",
      "Epoch 2 Batch 2130 Loss 2.4404 Accuracy 0.1571\n",
      "Epoch 2 Batch 2135 Loss 2.4406 Accuracy 0.1571\n",
      "Epoch 2 Batch 2140 Loss 2.4410 Accuracy 0.1572\n",
      "Epoch 2 Batch 2145 Loss 2.4407 Accuracy 0.1572\n",
      "Epoch 2 Batch 2150 Loss 2.4410 Accuracy 0.1572\n",
      "Epoch 2 Batch 2155 Loss 2.4411 Accuracy 0.1572\n",
      "Epoch 2 Batch 2160 Loss 2.4411 Accuracy 0.1573\n",
      "Epoch 2 Batch 2165 Loss 2.4408 Accuracy 0.1573\n",
      "Epoch 2 Batch 2170 Loss 2.4408 Accuracy 0.1573\n",
      "Epoch 2 Batch 2175 Loss 2.4407 Accuracy 0.1573\n",
      "Epoch 2 Batch 2180 Loss 2.4412 Accuracy 0.1573\n",
      "Epoch 2 Batch 2185 Loss 2.4413 Accuracy 0.1574\n",
      "Epoch 2 Batch 2190 Loss 2.4410 Accuracy 0.1574\n",
      "Epoch 2 Batch 2195 Loss 2.4410 Accuracy 0.1575\n",
      "Epoch 2 Batch 2200 Loss 2.4409 Accuracy 0.1574\n",
      "Epoch 2 Batch 2205 Loss 2.4405 Accuracy 0.1575\n",
      "Epoch 2 Batch 2210 Loss 2.4409 Accuracy 0.1575\n",
      "Epoch 2 Batch 2215 Loss 2.4412 Accuracy 0.1575\n",
      "Epoch 2 Batch 2220 Loss 2.4409 Accuracy 0.1575\n",
      "Epoch 2 Batch 2225 Loss 2.4406 Accuracy 0.1575\n",
      "Epoch 2 Batch 2230 Loss 2.4403 Accuracy 0.1575\n",
      "Epoch 2 Batch 2235 Loss 2.4398 Accuracy 0.1575\n",
      "Epoch 2 Batch 2240 Loss 2.4394 Accuracy 0.1576\n",
      "Epoch 2 Batch 2245 Loss 2.4392 Accuracy 0.1576\n",
      "Epoch 2 Batch 2250 Loss 2.4395 Accuracy 0.1576\n",
      "Epoch 2 Batch 2255 Loss 2.4401 Accuracy 0.1577\n",
      "Epoch 2 Batch 2260 Loss 2.4401 Accuracy 0.1577\n",
      "Epoch 2 Batch 2265 Loss 2.4403 Accuracy 0.1577\n",
      "Epoch 2 Batch 2270 Loss 2.4401 Accuracy 0.1578\n",
      "Epoch 2 Batch 2275 Loss 2.4393 Accuracy 0.1578\n",
      "Epoch 2 Batch 2280 Loss 2.4390 Accuracy 0.1578\n",
      "Epoch 2 Batch 2285 Loss 2.4391 Accuracy 0.1578\n",
      "Epoch 2 Batch 2290 Loss 2.4394 Accuracy 0.1578\n",
      "Epoch 2 Batch 2295 Loss 2.4393 Accuracy 0.1579\n",
      "Epoch 2 Batch 2300 Loss 2.4392 Accuracy 0.1578\n",
      "Epoch 2 Batch 2305 Loss 2.4394 Accuracy 0.1579\n",
      "Epoch 2 Batch 2310 Loss 2.4395 Accuracy 0.1579\n",
      "Epoch 2 Batch 2315 Loss 2.4393 Accuracy 0.1579\n",
      "Epoch 2 Batch 2320 Loss 2.4390 Accuracy 0.1579\n",
      "Epoch 2 Batch 2325 Loss 2.4388 Accuracy 0.1579\n",
      "Epoch 2 Batch 2330 Loss 2.4386 Accuracy 0.1579\n",
      "Epoch 2 Batch 2335 Loss 2.4382 Accuracy 0.1579\n",
      "Epoch 2 Batch 2340 Loss 2.4378 Accuracy 0.1580\n",
      "Epoch 2 Batch 2345 Loss 2.4375 Accuracy 0.1580\n",
      "Epoch 2 Batch 2350 Loss 2.4374 Accuracy 0.1580\n",
      "Epoch 2 Batch 2355 Loss 2.4369 Accuracy 0.1580\n",
      "Epoch 2 Batch 2360 Loss 2.4365 Accuracy 0.1580\n",
      "Epoch 2 Batch 2365 Loss 2.4366 Accuracy 0.1581\n",
      "Epoch 2 Batch 2370 Loss 2.4372 Accuracy 0.1581\n",
      "Epoch 2 Batch 2375 Loss 2.4370 Accuracy 0.1581\n",
      "Epoch 2 Batch 2380 Loss 2.4369 Accuracy 0.1582\n",
      "Epoch 2 Batch 2385 Loss 2.4366 Accuracy 0.1582\n",
      "Epoch 2 Batch 2390 Loss 2.4361 Accuracy 0.1582\n",
      "Epoch 2 Batch 2395 Loss 2.4359 Accuracy 0.1582\n",
      "Epoch 2 Batch 2400 Loss 2.4357 Accuracy 0.1582\n",
      "Epoch 2 Batch 2405 Loss 2.4352 Accuracy 0.1582\n",
      "Epoch 2 Batch 2410 Loss 2.4347 Accuracy 0.1582\n",
      "Epoch 2 Batch 2415 Loss 2.4338 Accuracy 0.1582\n",
      "Epoch 2 Batch 2420 Loss 2.4334 Accuracy 0.1582\n",
      "Epoch 2 Batch 2425 Loss 2.4335 Accuracy 0.1582\n",
      "Epoch 2 Batch 2430 Loss 2.4332 Accuracy 0.1583\n",
      "Epoch 2 Batch 2435 Loss 2.4330 Accuracy 0.1583\n",
      "Epoch 2 Batch 2440 Loss 2.4335 Accuracy 0.1583\n",
      "Epoch 2 Batch 2445 Loss 2.4333 Accuracy 0.1583\n",
      "Epoch 2 Batch 2450 Loss 2.4333 Accuracy 0.1583\n",
      "Epoch 2 Batch 2455 Loss 2.4329 Accuracy 0.1583\n",
      "Epoch 2 Batch 2460 Loss 2.4330 Accuracy 0.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 2465 Loss 2.4326 Accuracy 0.1583\n",
      "Epoch 2 Batch 2470 Loss 2.4323 Accuracy 0.1584\n",
      "Epoch 2 Batch 2475 Loss 2.4322 Accuracy 0.1584\n",
      "Epoch 2 Batch 2480 Loss 2.4318 Accuracy 0.1584\n",
      "Epoch 2 Batch 2485 Loss 2.4316 Accuracy 0.1584\n",
      "Epoch 2 Batch 2490 Loss 2.4315 Accuracy 0.1584\n",
      "Epoch 2 Batch 2495 Loss 2.4314 Accuracy 0.1584\n",
      "Epoch 2 Batch 2500 Loss 2.4312 Accuracy 0.1585\n",
      "Epoch 2 Batch 2505 Loss 2.4313 Accuracy 0.1585\n",
      "Epoch 2 Batch 2510 Loss 2.4310 Accuracy 0.1585\n",
      "Epoch 2 Batch 2515 Loss 2.4309 Accuracy 0.1586\n",
      "Epoch 2 Batch 2520 Loss 2.4312 Accuracy 0.1586\n",
      "Epoch 2 Batch 2525 Loss 2.4307 Accuracy 0.1586\n",
      "Epoch 2 Batch 2530 Loss 2.4308 Accuracy 0.1586\n",
      "Epoch 2 Batch 2535 Loss 2.4306 Accuracy 0.1586\n",
      "Epoch 2 Batch 2540 Loss 2.4306 Accuracy 0.1587\n",
      "Epoch 2 Batch 2545 Loss 2.4299 Accuracy 0.1587\n",
      "Epoch 2 Batch 2550 Loss 2.4302 Accuracy 0.1587\n",
      "Epoch 2 Batch 2555 Loss 2.4300 Accuracy 0.1587\n",
      "Epoch 2 Batch 2560 Loss 2.4294 Accuracy 0.1587\n",
      "Epoch 2 Batch 2565 Loss 2.4292 Accuracy 0.1588\n",
      "Epoch 2 Batch 2570 Loss 2.4287 Accuracy 0.1588\n",
      "Epoch 2 Batch 2575 Loss 2.4282 Accuracy 0.1588\n",
      "Epoch 2 Batch 2580 Loss 2.4278 Accuracy 0.1588\n",
      "Epoch 2 Batch 2585 Loss 2.4279 Accuracy 0.1588\n",
      "Epoch 2 Batch 2590 Loss 2.4278 Accuracy 0.1588\n",
      "Epoch 2 Batch 2595 Loss 2.4272 Accuracy 0.1589\n",
      "Epoch 2 Batch 2600 Loss 2.4269 Accuracy 0.1589\n",
      "Epoch 2 Batch 2605 Loss 2.4264 Accuracy 0.1589\n",
      "Epoch 2 Batch 2610 Loss 2.4265 Accuracy 0.1589\n",
      "Epoch 2 Batch 2615 Loss 2.4265 Accuracy 0.1589\n",
      "Epoch 2 Batch 2620 Loss 2.4264 Accuracy 0.1589\n",
      "Epoch 2 Batch 2625 Loss 2.4261 Accuracy 0.1589\n",
      "Epoch 2 Batch 2630 Loss 2.4260 Accuracy 0.1590\n",
      "Epoch 2 Batch 2635 Loss 2.4256 Accuracy 0.1590\n",
      "Epoch 2 Batch 2640 Loss 2.4259 Accuracy 0.1590\n",
      "Epoch 2 Batch 2645 Loss 2.4253 Accuracy 0.1590\n",
      "Epoch 2 Batch 2650 Loss 2.4252 Accuracy 0.1590\n",
      "Epoch 2 Batch 2655 Loss 2.4244 Accuracy 0.1591\n",
      "Epoch 2 Batch 2660 Loss 2.4240 Accuracy 0.1590\n",
      "Epoch 2 Batch 2665 Loss 2.4236 Accuracy 0.1591\n",
      "Epoch 2 Batch 2670 Loss 2.4236 Accuracy 0.1591\n",
      "Epoch 2 Batch 2675 Loss 2.4235 Accuracy 0.1591\n",
      "Epoch 2 Batch 2680 Loss 2.4231 Accuracy 0.1591\n",
      "Epoch 2 Batch 2685 Loss 2.4227 Accuracy 0.1591\n",
      "Epoch 2 Batch 2690 Loss 2.4222 Accuracy 0.1591\n",
      "Epoch 2 Batch 2695 Loss 2.4220 Accuracy 0.1591\n",
      "Epoch 2 Batch 2700 Loss 2.4214 Accuracy 0.1591\n",
      "Epoch 2 Batch 2705 Loss 2.4207 Accuracy 0.1592\n",
      "Epoch 2 Batch 2710 Loss 2.4207 Accuracy 0.1592\n",
      "Epoch 2 Batch 2715 Loss 2.4204 Accuracy 0.1592\n",
      "Epoch 2 Batch 2720 Loss 2.4205 Accuracy 0.1592\n",
      "Epoch 2 Batch 2725 Loss 2.4203 Accuracy 0.1592\n",
      "Epoch 2 Batch 2730 Loss 2.4205 Accuracy 0.1592\n",
      "Epoch 2 Batch 2735 Loss 2.4203 Accuracy 0.1592\n",
      "Epoch 2 Batch 2740 Loss 2.4203 Accuracy 0.1593\n",
      "Epoch 2 Batch 2745 Loss 2.4202 Accuracy 0.1593\n",
      "Epoch 2 Batch 2750 Loss 2.4200 Accuracy 0.1593\n",
      "Epoch 2 Batch 2755 Loss 2.4199 Accuracy 0.1593\n",
      "Epoch 2 Batch 2760 Loss 2.4191 Accuracy 0.1593\n",
      "Epoch 2 Batch 2765 Loss 2.4188 Accuracy 0.1594\n",
      "Epoch 2 Batch 2770 Loss 2.4190 Accuracy 0.1594\n",
      "Epoch 2 Batch 2775 Loss 2.4195 Accuracy 0.1595\n",
      "Epoch 2 Batch 2780 Loss 2.4188 Accuracy 0.1594\n",
      "Epoch 2 Batch 2785 Loss 2.4188 Accuracy 0.1595\n",
      "Epoch 2 Batch 2790 Loss 2.4187 Accuracy 0.1595\n",
      "Epoch 2 Batch 2795 Loss 2.4187 Accuracy 0.1595\n",
      "Epoch 2 Batch 2800 Loss 2.4187 Accuracy 0.1595\n",
      "Epoch 2 Batch 2805 Loss 2.4188 Accuracy 0.1596\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/train/ckpt-2\n",
      "Epoch 2 Loss 2.4184 Accuracy 0.1595\n",
      "Time taken for 1 epoch: 562.7504549026489 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 5== 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 1 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# The following steps are used for evaluation:\n",
    "\n",
    "# Encode the input sentence using the Portuguese tokenizer (tokenizer_pt). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "# The decoder input is the start token == tokenizer_en.vocab_size.\n",
    "# Calculate the padding masks and the look ahead masks.\n",
    "# The decoder then outputs the predictions by looking at the encoder output and its own output (self-attention).\n",
    "# Select the last word and calculate the argmax of that.\n",
    "# Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "# In this approach, the decoder predicts the next word based on the previous words it predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if tf.equal(predicted_id, tokenizer_en.vocab_size+1):\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: so my father was my own life .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i think about a little bit about the first time that i think about the right of the right way .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first example of the first example of the first time .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
